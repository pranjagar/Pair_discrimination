{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import cmath\n",
    "import sympy as sym\n",
    "import scipy as sci\n",
    "import matplotlib.ticker as ticker\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import cmath as cm\n",
    "from IPython.display import display, Latex\n",
    "from sympy import pprint\n",
    "# from scipy.optimize import minimize as GDlib\n",
    "from scipy.optimize import minimize \n",
    "import MLE_functions_numpy as fn\n",
    "from MLE_functions_numpy import *\n",
    "from scipy.optimize import fsolve\n",
    "import pandas as pd\n",
    "import MLE_functions_numpy as fnn\n",
    "# from minimize import least_squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explicitly writing all the intermediate values in the inversion function to spot the error in fidelities.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the error is narrowed down to difference in the theoretical numerical density matrices which comes from num experiment function. \n",
    "exploring it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_tru2 = fnn.Creating_states(tru2)\n",
    "expt = fnn.num_experiment(params = tru2, nju = bad_nju)\n",
    "\n",
    "\n",
    "st_1 = states_tru2[0]\n",
    "# st_2 = expt[0]\n",
    "\n",
    "stst = states_tru2[1]\n",
    "\n",
    "print('','rho_th:',)\n",
    "rho = states_tru2[2]\n",
    "print(rho)\n",
    "\n",
    "r = expt[1]\n",
    "r_n = expt[2]\n",
    "p = expt[3]\n",
    "n = expt[4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FixED!! Moving back to debugging the inversion function, , specifically the problem of possibile flipping of the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So apparently the error turns out to be in the order of elements of the eigenvector of concern which is the xi eigenvector and apparently the first and the second elements are flipped for that we expect the un flipped versions because the reason that very small perturbation from the actual theoretical matrix should only result in a small perturbation in the eigenvectors and not a huge one as it seems to be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying many collapse vectors at random and seeing for how many of them the Xi vector is \"inverted\" in the corresponding coeffs and fids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking likelihood function for bad njus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru6 = [m.pi/2+m.pi/12, m.pi/2+ m.pi/6, 0, m.pi/2, m.pi/12]\n",
    "coll6 = fnn.generate_collapses(tru6, 5000, 100)\n",
    "\n",
    "for i in coll6:\n",
    "    err4_i = fnn.ppm_errors(tru6, i)\n",
    "    if sum(err4_i[0])>400000:\n",
    "        print('more', err4_i)\n",
    "        print('more', i)\n",
    "    if sum(err4_i[0])<30000:\n",
    "        print('less!', err4_i)\n",
    "        print('less', i)\n",
    "\n",
    "\n",
    "# more [[1083.1074292144694, 598711.0534063264], [1928.8616851780293, 619300.2918287966]]\n",
    "# [[1258.3445740775855, 951200.5509476968], [462.0747215567933, 951200.5509476968]]\n",
    "# [[840.6540047416478, 749944.5203257491], [898.3376353625116, 765841.7839133753]]\n",
    "\n",
    "bnj1 = [1307, 144, 712, 473, 103, 756, 612, 133, 760]\n",
    "bnj2 = [1444, 148, 617, 519, 95, 777, 600, 123, 677]\n",
    "bnj3 = [1342, 169, 667, 490, 99, 750, 594, 103, 786]\n",
    "less1= [1366, 148, 654, 511, 89, 760, 619, 126, 727]\n",
    "[1339.3, 161.928, 638.95, 525.47, 91.883, 753.33, 614.28, 121.488, 753.3386257884266]\n",
    "\n",
    "[i*5000 for i in fnn.pr_num(tru6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing likelihood functions for the abobve bad values\n",
    "L1_m = fnn.L(vars = False, n = bnj1)\n",
    "L1 = fnn.L(vars = tru6, n = bnj1)\n",
    "\n",
    "# do same for following\n",
    "\n",
    "# [[0.0, 957209.8391575121], [733.1377895182234, 856342.752447464]]\n",
    "# [645, 6, 650, 619, 4, 697, 706, 7, 666]\n",
    "\n",
    "# [[0.0, 981256.4527567336], [62.809710090316884, 829699.8641764291]]\n",
    "# [666, 7, 683, 645, 4, 649, 668, 9, 669]\n",
    "\n",
    "# less! [[0.0, 6852.582189213807], [60756.135037916545, 146949.14959349524]]\n",
    "# less [661, 4, 631, 661, 7, 671, 681, 3, 681]\n",
    "\n",
    "\n",
    "L2_m = fnn.L(vars = False, n = bnj2)\n",
    "L2 = fnn.L(vars = tru6, n = bnj2)\n",
    "\n",
    "L3_m = fnn.L(vars = False, n = bnj3)\n",
    "L3 = fnn.L(vars = tru6, n = bnj3)\n",
    "\n",
    "\n",
    "\n",
    "print([L1_m, L1])\n",
    "print([L2_m, L2])\n",
    "print([L3_m, L3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn.ppm_errors(tru6, [1307, 144, 712, 473, 103, 756, 612, 133, 760])\n",
    "\n",
    "prams1 = [1.33073649+0.00000000e+00j,  0.17024566+0.00000000e+00j,2.9826044 +0.00000000e+00j, -0.93498342+0.00000000e+00j,0.21936886-1.21965119e-17j]\n",
    "\n",
    "\n",
    "bnj1 = [1307, 144, 712, 473, 103, 756, 612, 133, 760]\n",
    "bnj2 = [1444, 148, 617, 519, 95, 777, 600, 123, 677]\n",
    "bnj3 = [1342, 169, 667, 490, 99, 750, 594, 103, 786]\n",
    "less1= [1366, 148, 654, 511, 89, 760, 619, 126, 727]\n",
    "\n",
    "# fun = fnn.L(vars = prams1, n = bnj1)\n",
    "# fun\n",
    "\n",
    "L_tru6 = fnn.L(vars = tru6, n = bnj1)\n",
    "print(L_tru6)\n",
    "\n",
    "# MARTIN CASE\n",
    "# opt.AuxParams={{0.2614,0.0288,0.1424,0.0946,0.0206,0.1512,0.1224,0.0266,0.152}}\n",
    "# case6(MIT): {theta1,theta2,phi1,phi2,alpha}={{1.33073649,0.17024566,-2.9826044,-0.93498342,0.21936886}}\n",
    "#  ---> NYFunction = 1.959768143157167\n",
    "bnjn1 = [i/sum(bnj1) for i in bnj1]\n",
    "prob_params = fnn.pr_num([1.33073649,0.17024566,-2.9826044,-0.93498342,0.21936886])\n",
    "prob_params = [0.25526472341208967, 0.02896871461128489, 0.1333327431548282, 0.0969470432734706, 0.020183709309324616, 0.15304763238431282, 0.1239280379744138, 0.026836900566235833, 0.16149049531404092]\n",
    "log_prob_params = [m.log(i) for i in prob_params]\n",
    "L_list = [m.log(i)*j for i,j in zip(prob_params, bnjn1)]\n",
    "L = sum(L_list)\n",
    "L\n",
    "\n",
    "# fucntion output\n",
    "Lf = fnn.L(vars = [1.33073649,0.17024566,-2.9826044,-0.93498342,0.21936886], n = bnj1)\n",
    "Lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0.17050398243083,4.4722844667216,5.3576515384017,3.3006005582285,1.7900422339236]\n",
    "fn.fid([a[1],a[0],a[3],a[2],a[4]], tru6)\n",
    "\n",
    "# [[1083.1074292144694, 598711.0534063264], [1928.8616851780293, 619300.2918287966]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckingCMatrix(index = [0,0], psi = [1,0], psi2 = [0,1], p = [.5,.5]):\n",
    "    sigma_x = np.array([[0, 1], [1, 0]])    # 2d matrices in the comp  basis\n",
    "    sigma_y = np.array([[0, -1j], [1j, 0]])\n",
    "    sigma_z = np.array([[1, 0], [0, -1]])\n",
    "    \n",
    "    matrices = np.array([sigma_x, sigma_y, sigma_z])\n",
    "    # print('list paulis=\\n', matrices)\n",
    "\n",
    "    R_matrix = (1/np.sqrt(2))*np.array([[np.sqrt(2),0,0,0],[0,1,-1,0],[0,1,1,0],[0,0,0,np.sqrt(2)]])\n",
    "    R_matrix_inverse = np.linalg.inv(R_matrix) \n",
    "    sigma_x_tilda_comp = np.kron(sigma_x , np.identity(2))\n",
    "    sigma_y_tilda_comp = np.kron(sigma_y , np.identity(2))\n",
    "    sigma_z_tilda_comp = np.kron(sigma_z , np.identity(2))\n",
    "    sigma_x_tilda = np.dot(np.dot(R_matrix ,sigma_x_tilda_comp), R_matrix_inverse)\n",
    "    sigma_y_tilda = np.dot(np.dot(R_matrix ,sigma_y_tilda_comp), R_matrix_inverse)\n",
    "    sigma_z_tilda = np.dot(np.dot(R_matrix ,sigma_z_tilda_comp), R_matrix_inverse)\n",
    "\n",
    "    tensor_sigma_ij_comp = np.kron(matrices[index[0]], matrices[index[1]])\n",
    "    print(f\"\\ntensor_sigma_comp_{index}\\n\",tensor_sigma_ij_comp)\n",
    "\n",
    "    tensor_sigma_ij_tilda = np.dot(np.dot(R_matrix, tensor_sigma_ij_comp), R_matrix_inverse)\n",
    "    print(f\"\\ntensor_sigma_{index}_tilda\\n\",tensor_sigma_ij_tilda)\n",
    "    \n",
    "    rho1_comp = np.outer(np.kron(psi, psi),np.kron(psi, psi))\n",
    "    rho2_comp = np.outer(np.kron(psi2, psi2),np.kron(psi2, psi2))\n",
    "    rho1_tilda = np.dot(np.dot(R_matrix ,rho1_comp), R_matrix_inverse)\n",
    "    rho2_tilda = np.dot(np.dot(R_matrix ,rho2_comp), R_matrix_inverse)\n",
    "\n",
    "    rho_mixed_comp = p[0]*rho1_comp + p[1]*rho2_comp\n",
    "    rho_mixed_tilda = p[0]*rho1_tilda + p[1]*rho2_tilda\n",
    "\n",
    "\n",
    "    print(\"\\n rho_1_comp = \\n\", rho1_comp)\n",
    "    print(\"\\n rho_2_comp = \\n\", rho2_comp)\n",
    "    print(\"\\nrho_mixed_comp = \\n\", rho_mixed_comp)\n",
    "    print(\"\\nrho_mixed_tild = \\n\", rho_mixed_tilda)\n",
    "\n",
    "    C_ij = np.trace(np.dot(tensor_sigma_ij_tilda, rho_mixed_tilda))\n",
    "    print(f\" \\nElement C_{index}\\n\", C_ij)\n",
    "\n",
    "    \n",
    "    # print(f\"tensor_sigma_{index}_tilda\\n\",tensor_sigma_ij_tilda)\n",
    "\n",
    "\n",
    "\n",
    "# CheckingCMatrix()\n",
    "# CheckingCMatrix(psi = [.5, np.sqrt(3)/2], psi2= [ np.sqrt(3)/2, .5], index = [2,2]) # using the rotation method of change of basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w = m.e**((2/3)*m.pi*(1j))     # third root of unity\n",
    "POVM_vec = (1/(2**.5))*(np.array([[0,1,-1],[-1,0,1],[1,-1,0],[0,w,-w**2],[-1,0,w**2],[1,-w,0],[0,w**2,-w],[-1,0,w],[1,-w**2,0]]))  # an array of POVM direction vectors\n",
    "POVM_elts = [(1/3)*np.outer(np.conjugate(POVM_vec[i]),POVM_vec[i]) for i in range(len(POVM_vec))]   # a list of POVM matrices\n",
    "M = [[np.trace(np.dot(POVM_elts[i],POVM_elts[j])) for i in range(len(POVM_elts))] for j in range(len(POVM_elts))]     # creating M matrix using POVM definition\n",
    "u_0 = [1/3 for i in range(9)]           # cerating u_0 vector, to create the inverse matrix\n",
    "M_inv = 3*np.outer(u_0,u_0) + 12*(np.eye(9) - np.outer(u_0,u_0))        # creating the inverse matrix\n",
    "\n",
    "\n",
    "def num_experiment(N = 10000, params = [0,m.pi/2,0,0,m.pi/4], show_calcs = False, seed = None):\n",
    "    creation = fn.Creating_states( params = params, Abstract = 0) # theoretical rho\n",
    "    states = creation[0]\n",
    "    sq_states = creation[1]\n",
    "    rho = creation[2]\n",
    "    # print(rho)\n",
    "    # print(states)\n",
    "    prob_vec_sympy_0 =  [np.trace(np.dot(POVM_elts[i],rho)) for i in range(9)]    # created list of Th probabilities\n",
    "    prob_vec_sympy = [i.evalf() for i in prob_vec_sympy_0]  # evaluated the sympy expressions\n",
    "    prob_vec = [np.complex64(i) for i in prob_vec_sympy]  # converted to regular complex numbers\n",
    "    # prob_vec_raw = [(float(i.as_real_imag()[0])+float(i.as_real_imag()[1])*1j) for i in prob_vec_sympy]  # this is to avoid error, to convert sympy float to ordinary number\n",
    "    # prob_vec = [round(i.real, 10) for i in prob_vec_raw if abs(i.imag) < .0001]          # cleaned up theoretical prob vector\n",
    "    # prob_vec = prob_vec_sympy\n",
    "    \n",
    "    print('rho\\n')\n",
    "    pprint(rho)\n",
    "    print('prob_vec_sympy_0\\n', prob_vec_sympy_0)\n",
    "    print('prob_vec_sympy\\n', prob_vec_sympy)\n",
    "    print('prob_vec\\n', prob_vec)\n",
    "    print('prob_vec\\n', prob_vec)\n",
    "    print('sum prob_vec\\n', sum(prob_vec))\n",
    "    # print('prob_vec_raw\\n', prob_vec_raw)    \n",
    "\n",
    "    POVM_dir_symbols = ['d1','d2','d3','d4','d5','d6','d7','d8','d9']      # symbols to indicate collapsed direction\n",
    "    #prob distribution is simply the corresponding elements of the prob_vec\n",
    "    collapse_dir_vec = rand.choices(POVM_dir_symbols, weights=prob_vec, k = N)   # choosing collapse directions with weights for N trials\n",
    "    nj_vec = [collapse_dir_vec.count(f'd{i+1}') for i in range(9)]\n",
    "    pj_num_vec = [i/N for i in nj_vec]                                  # numerical prob vector     \n",
    "\n",
    "    r_vec = np.dot(M_inv,pj_num_vec)\n",
    "    rho_num_list = [r_vec[i]*POVM_elts[i] for i in range(len(POVM_elts))]   # list of matrices, see equation 7 in notes pair_disc.pdf\n",
    "    rho_num = np.zeros_like(rho_num_list[0])\n",
    "    # Loop for reconstructing the numerical matrix\n",
    "    for i in rho_num_list:\n",
    "        rho_num = np.add(rho_num, i)\n",
    "    \n",
    "\n",
    "    \n",
    "    return [states, rho, rho_num, prob_vec, nj_vec]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_i = [.1, m.pi/2+.1, .1, .1, m.pi/4+.1]\n",
    "params_i = [0, m.pi/2+.1, .1, .1, m.pi/4]\n",
    "nj_unnorm = num_experiment(params= params_i, N = 10000)[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging the complex probabilities\n",
    "\n",
    "\n",
    "def num_experiment(N = 10000, params = [0,m.pi/2,0,0,m.pi/4], seed = None, an_pr = False):\n",
    "    if seed is not None:\n",
    "        rand.seed(seed)\n",
    "    \n",
    "    creation = fn.Creating_states( params = params, Abstract = 0) # theoretical rho\n",
    "    states = creation[0]\n",
    "    sq_states = creation[1]\n",
    "    rho = creation[2]\n",
    "    # print(rho)\n",
    "    # print(states)\n",
    "    prob_vec_sympy =  [np.trace(np.dot(fn.POVM_elts[i],rho)) for i in range(9)]    # created list of Th probabilities\n",
    "    prob_vec_raw = [(float(i.as_real_imag()[0])+float(i.as_real_imag()[1])*1j) for i in prob_vec_sympy]  # this is to avoid error, to convert sympy float to ordinary number\n",
    "    prob_vec = [round(i.real, 10) for i in prob_vec_raw if abs(i.imag) < .0001]          # cleaned up theoretical prob vector\n",
    "    if an_pr == True:\n",
    "        prob_vec = [i.subs({fn.theta1: params[0], fn.theta2: params[1], fn.phi1:params[2], fn.phi2: params[3], fn.alpha: params[4]}) for i in fn.pr]  # using prof hillery's analytic probabilities\n",
    "        prob_vec = [round(i.evalf(), 12) for i in prob_vec]\n",
    "\n",
    "    POVM_dir_symbols = ['d1','d2','d3','d4','d5','d6','d7','d8','d9']      # symbols to indicate collapsed direction\n",
    "    #prob distribution is simply the corresponding elements of the prob_vec\n",
    "    collapse_dir_vec = rand.choices(POVM_dir_symbols, weights=prob_vec, k = N)   # choosing collapse directions with weights for N trials\n",
    "    nj_vec = [collapse_dir_vec.count(f'd{i+1}') for i in range(9)]\n",
    "    pj_num_vec = [i/N for i in nj_vec]                                  # numerical prob vector     \n",
    "\n",
    "    r_vec = np.dot(fn.M_inv,pj_num_vec)\n",
    "    rho_num_list = [r_vec[i]*fn.POVM_elts[i] for i in range(len(fn.POVM_elts))]   # list of matrices, see equation 7 in notes pair_disc.pdf\n",
    "    rho_num = np.zeros_like(rho_num_list[0])\n",
    "    # Loop for reconstructing the numerical matrix\n",
    "    for i in rho_num_list:\n",
    "        rho_num = np.add(rho_num, i)\n",
    "    \n",
    "    return [states, rho, rho_num, prob_vec, nj_vec]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a code to create random lists of 5 integers and use the prnum function, then sum it and then only add to the list if it exceeds 1.\n",
    "error_p = []\n",
    "error_params = []\n",
    "for i in range(1000000):\n",
    "    p_i = np.random.rand(5)*m.pi\n",
    "    probs_list = [i(*p_i) for i in pr_num]   \n",
    "    if sum(probs_list) > 1+ 1e-14 or sum(probs_list) < 1-1e-14:\n",
    "        print(sum(probs_list))\n",
    "        print(probs_list)\n",
    "        error_p.append(probs_list)\n",
    "        error_params.append(p_i)\n",
    "print(error_p)\n",
    "print(error_params)\n",
    "# Here we checked randomly at 10 million points in the parameter space to find anomalies in the probability sum \n",
    "# but it is summing out to be correct up to 14 digits after 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing the newly converted functions from simpy to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru2\n",
    "# parameters for two orthogonal states\n",
    "params = [0, m.pi/2, 0, 0, m.pi/4]\n",
    "params1 = [0,m.pi/4, 0, m.pi, m.pi/4]\n",
    "\n",
    "\n",
    "fnn.Creating_states(params1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn.fid([0, m.pi/2, 0, m.pi/2, m.pi/12], [0, m.pi/2+m.pi/12, 0, 0, m.pi/4]) \n",
    "\n",
    "# np.cos(m.pi/12)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for errors:\n",
    "*similar parameters yet almost zero fidelity\n",
    "\n",
    "*anomalous cases when cross entropy is lesser than the theoretical minimum using inversion but not with random ig\n",
    "\n",
    "*finally matching Martin's results with my own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# studying the case of tru2 : [m.pi/4, m.pi/2+m.pi/4, m.pi/2, m.pi/4, m.pi/3]\n",
    "\n",
    "tru2 = [m.pi/4, m.pi/2+m.pi/4, m.pi/2, m.pi/4, m.pi/3]\n",
    "nju2 = [1856,1834,1073,660,646,204,1236,1260,1231]\n",
    "print(10000- sum(nju2))\n",
    "\n",
    "# generated = fnn.generate_collapses(tru2, 10000, 50)\n",
    "nju2 = [i for i in generated]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1860, 1910, 1066, 598, 648, 165, 1240, 1247, 1266]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([7.07106781e-01+0.j        , 4.32978028e-17+0.70710678j]),\n",
       " array([-0.70710678+0.j ,  0.5       +0.5j])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(nju2[0]) = [1860, 1910, 1066, 598, 648, 165, 1240, 1247, 1266]\n",
    "Creating_states(tru2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000945677395038491, 0.4913937768143437], [0.000945677395038491, 0.4913937768143437], [0.9990543226049614, 0.9999100813352145]]\n",
      "[[0.0003591654647820573, 0.5032491493594297], [0.0003591654647820573, 0.5032491493594297], [0.999640834535218, 0.9999880005350892]]\n",
      "[[0.0008593606088623875, 0.49673650468595787], [0.0008593606088623875, 0.49673650468595787], [0.9991406393911376, 0.9998005570212718]]\n",
      "[[0.0010823632352193488, 0.5051870688694133], [0.0010823632352193488, 0.5051870688694133], [0.9989176367647805, 0.9999730001052315]]\n",
      "[[8.618552661441018e-05, 0.4938600296901367], [8.618552661441018e-05, 0.4938600296901367], [0.9999138144733857, 0.999962136148639]]\n",
      "[[0.00032214264106637683, 0.4996507069229167], [0.00032214264106637683, 0.4996507069229167], [0.9996778573589334, 0.9998158038859359]]\n",
      "[[0.00040806499672303915, 0.5017274515373373], [0.00040806499672303915, 0.5017274515373373], [0.999591935003277, 0.9999463995836076]]\n",
      "[[0.000157025136903935, 0.5116636132946889], [0.000157025136903935, 0.5116636132946889], [0.9998429748630959, 0.9998621705291222]]\n",
      "[[0.0006560962237584292, 0.49436334355522843], [0.0006560962237584292, 0.49436334355522843], [0.9993439037762415, 0.999917017903532]]\n",
      "[[0.0018848684503247018, 0.5004844271921514], [0.0018848684503247018, 0.5004844271921514], [0.9981151315496753, 0.999999171290396]]\n",
      " \n",
      "\n",
      "\n",
      "[ 0.7556077  -0.78112345  1.5632762   0.80659345  1.05913301]\n",
      "[2.35692667 0.77618324 0.7862566  1.53751861 0.5209409 ]\n",
      "[-0.79846478  0.77667628  0.79489847  1.61193886  0.5258888 ]\n",
      "[2.35531048 0.81328141 0.76364441 1.54343234 0.5236937 ]\n",
      "[ 0.78646445 -0.78027495  3.93389046 -1.55579114  0.51068217]\n",
      "[0.79729765 0.76471972 3.9312929  1.56315321 0.52344557]\n",
      "[-0.78208627  0.7925747   0.7850694   1.52185529  0.53910339]\n",
      "[ 0.78797582 -0.78324465  1.5364456   0.77116291  1.04267147]\n",
      "[ 2.36451726 -0.79581906  4.68190002  0.7889878   1.04878414]\n",
      "[-0.7816962   0.7980124   0.77517273  1.5481392   2.62435184]\n"
     ]
    }
   ],
   "source": [
    "for i in nju2[:10]:\n",
    "    invi = Inversion_new(params = tru2, nju = i)[0]\n",
    "    print(invi)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13905318132646846, 0.14439432753282003]\n",
      "[0.13905318132646846, 0.14439432753282003]\n",
      "[0.13905318132646846, 0.14439432753282003]\n",
      "[0.13905318132646846, 0.14439432753282003]\n",
      "[0.13905318132646846, 0.14439432753282003]\n",
      "[0.13905318132646846, 0.14439432753282003]\n",
      "[0.13905318132646846, 0.14439432753282003]\n",
      "[0.13905318132646846, 0.14439432753282003]\n",
      "[0.13905318132646846, 0.14439432753282003]\n",
      "[0.13905318132646846, 0.14439432753282003]\n"
     ]
    }
   ],
   "source": [
    "# print('','\\n\\n',)\n",
    "#optimizing emthod\n",
    "for i in nju2[:10]:\n",
    "    opti = minimize(L, np.random.rand(5) , method = 'CG' , args=(i))\n",
    "    fids = fnn.fid(params1 = opti.x, params2 = tru2)\n",
    "    print(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9990964469301689, 0.9998697819988115]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
