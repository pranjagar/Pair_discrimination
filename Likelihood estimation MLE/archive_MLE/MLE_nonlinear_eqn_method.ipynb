{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import cmath\n",
    "import sympy as sym\n",
    "import scipy as sci\n",
    "import matplotlib.ticker as ticker\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import cmath as cm\n",
    "from IPython.display import display, Latex\n",
    "from sympy import pprint\n",
    "from scipy.optimize import minimize as GDlib\n",
    "import MLE_functions as fn\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1, theta2, phi1, phi2, alpha = sym.symbols('theta1 theta2 phi1 phi2 alpha')\n",
    "c1, c2, s1, s2, w1, w2 = sym.cos(theta1), sym.cos(theta2), sym.sin(theta1), sym.sin(theta2), sym.cos(alpha)**2, sym.sin(alpha)**2\n",
    "\n",
    "# # analytic formuale for the probabilities, as given in the notes\n",
    "pr1 = (1/6)*(w1*s1**2*(1+c1**2 -2*m.sqrt(2)*sym.cos(phi1)*s1*c1)+w2*s2**2*(1+c2**2-2*m.sqrt(2)*sym.cos(phi2)*s2*c2))\n",
    "pr2 = (1/6)*(w1*c1**2*(1+s1**2 -2*m.sqrt(2)*sym.cos(phi1)*c1*s1) + w2*c2**2*(1+s2**2*-2*m.sqrt(2)*sym.cos(phi2)*c2*s2))\n",
    "pr3 = (1/6)*(w1*(c1**4+s1**4 -2*sym.cos(2*phi1)*s1**2*c1**2)+ w2*(c2**4+ s2**4 - 2*sym.cos(2*phi2)*s2**2*c2**2))\n",
    "pr4 = (1/6)*(w1*s1**2*(1+c1**2 -2*m.sqrt(2)*sym.cos(phi1+2*m.pi/3)*s1*c1)+ w2*s2**2*(1+c2**2-2*m.sqrt(2)*sym.cos(phi2+2*m.pi/3)*s2*c2))\n",
    "# pr5= (1/6)* (w1*c1**2*(1+s1**2 -2*m.sqrt(2)*sym.cos(phi1-2*m.pi/3)*c1*s1)+ w2*c2**2*(1+s2**2-2*m.sqrt(2)*sym.cos(phi2-2*m.pi/3)*c2*s2))\n",
    "pr5= (1/6)* (w1*c1**2*(1+s1**2 -2*m.sqrt(2)*sym.cos(phi1+2*m.pi/3)*c1*s1)+ w2*c2**2*(1+s2**2-2*m.sqrt(2)*sym.cos(phi2+2*m.pi/3)*c2*s2))\n",
    "# pr6 = (1/6)*(w1*(c1**4+s1**4-2*sym.cos(2*phi1 - 2*m.pi/3)*c1**2*s1**2)+ w2*(c2**4+s2**4-2*sym.cos(2*phi2 - 2*m.pi/3)*c2**2*s2**2))\n",
    "pr6 = (1/6)*(w1*(c1**4+s1**4-2*sym.cos(2*phi1 +2*m.pi/3)*c1**2*s1**2)+ w2*(c2**4+s2**4-2*sym.cos(2*phi2 +2*m.pi/3)*c2**2*s2**2))\n",
    "pr7 = (1/6)*(w1*s1**2*(1+c1**2-2*m.sqrt(2)*sym.cos(phi1-2*m.pi/3)*s1*c1)+ w2*s2**2*(1+c2**2-2*m.sqrt(2)*sym.cos(phi2-2*m.pi/3)*s2*c2))\n",
    "pr8 = (1/6)*(w1*c1**2*(1+s1**2-2*m.sqrt(2)*sym.cos(phi1-2*m.pi/3)*c1*s1)+ w2*c2**2*(1+s2**2-2*m.sqrt(2)*sym.cos(phi2-2*m.pi/3)*c2*s2))\n",
    "pr9 = (1/6)*(w1*(c1**4+s1**4-2*sym.cos(2*phi1+2*m.pi/3)*c1**2*s1**2)+ w2*(c2**4+s2**4-2*sym.cos(2*phi2+2*m.pi/3)*c2**2*s2**2))\n",
    "pr = [pr1, pr2,pr3, pr4,pr5, pr6,pr7, pr8,pr9]      # list of analytic prob.\n",
    "\n",
    "w = m.e**((2/3)*m.pi*(1j))     # third root of unity\n",
    "POVM_vec = (1/(2**.5))*(np.array([[0,1,-1],[-1,0,1],[1,-1,0],[0,w,-w**2],[-1,0,w**2],[1,-w,0],[0,w**2,-w],[-1,0,w],[1,-w**2,0]]))  # an array of POVM direction vectors\n",
    "POVM_elts = [(1/3)*np.outer(np.conjugate(POVM_vec[i]),POVM_vec[i]) for i in range(len(POVM_vec))]   # a list of POVM matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.0833333333333333$"
      ],
      "text/plain": [
       "0.0833333333333333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr1.subs({theta1:0, theta2:m.pi/2, phi1:0, phi2:0, alpha:m.pi/4})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0401666666666667,\n",
       " 0.0340666666666667,\n",
       " -0.121866666666667,\n",
       " -0.0376666666666667,\n",
       " 0.0302666666666667]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def equations_th_prob(vars):                                        # equations are simply (p_j - n_j). p_j are the (substiuted) probabilities.\n",
    "    t1, t2, p1, p2, a = vars[:5]\n",
    "    # c1, c2, s1, s2, w1, w2 = sym.cos(theta1), sym.cos(theta2), sym.sin(theta1), sym.sin(theta2), sym.cos(alpha)**2, sym.sin(alpha)**2\n",
    "    n_unnorm = [142, 128, 426, 2117, 1235, 1326, 2052, 1210, 1364]   # to be changed each time\n",
    "    # correct_variables =  [m.pi/4, m.pi/2-m.pi/8 , 0,0, m.pi/4]     # the right answer, for the supposed n vector. just for tracking purposes\n",
    "    n = [i/sum(n_unnorm) for i in n_unnorm]                          # normalise the counts\n",
    "    \n",
    "    eqs_pr = [i.subs({theta1: t1, theta2: t2, phi1: p1, phi2: p2 , alpha: a}).evalf() for i in pr]\n",
    "    eqs    = [eqs_pr[i] - n[i] for i in range(len(n))]                  # final equations\n",
    "    return eqs[4:]\n",
    "    \n",
    "equations_th_prob([0, m.pi/2, 0, 0, m.pi/4])   # just to check if the function is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_num = [sym.lambdify((theta1, theta2, phi1, phi2, alpha), i) for i in pr]   # lambdify the probabilities\n",
    "\n",
    "def eq_pr_num(vars):\n",
    "    n_unnorm = [142, 128, 426, 2117, 1235, 1326, 2052, 1210, 1364]   # to be changed each time\n",
    "    n = [i/sum(n_unnorm) for i in n_unnorm]                          # normalise the counts\n",
    "    eq_pr = [pr_num[i](*vars) for i in range(len(pr_num))]\n",
    "    eq = [eq_pr[i] - n[i] for i in range(len(n))]\n",
    "    return eq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution :  [8.85398163e-01 1.17809725e+00 0.00000000e+00 1.00000000e-03\n",
      " 7.85398163e-01]\n",
      "sum of the absolute values of the residuals :  0.0541947243309272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_minpack_py.py:177: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"# solving using fsolve\\nsol_list = []\\nfor i in range(10):\\n    initial_guess = list(np.random.rand(5))\\n    initial_guess = initial_guess + [0,0,0,0]\\n    solution = fsolve(equations_th_prob, initial_guess)\\n    sol_list.append(solution)\\n\\nfunc_list = [sum([abs(j) for j in equations_th_prob(i)]) for i in sol_list]         # list for each solution, each term is the sum of the absolute values of (p_j-n_j)\\nprint('','values : \\n ', func_list)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inv_guess = [m.pi/4+.1, m.pi/2-m.pi/8 , 0,.001, m.pi/4]    # initial guess for the variables, and the rest are dummy zeros\n",
    "solution = fsolve(equations_th_prob, inv_guess)\n",
    "print('solution : ', solution)\n",
    "print('sum of the absolute values of the residuals : ', sum([abs(i) for i in equations_th_prob(solution)]))\n",
    "\n",
    "\n",
    "\"\"\"# solving using fsolve\n",
    "sol_list = []\n",
    "for i in range(10):\n",
    "    initial_guess = list(np.random.rand(5))\n",
    "    initial_guess = initial_guess + [0,0,0,0]\n",
    "    solution = fsolve(equations_th_prob, initial_guess)\n",
    "    sol_list.append(solution)\n",
    "\n",
    "func_list = [sum([abs(j) for j in equations_th_prob(i)]) for i in sol_list]         # list for each solution, each term is the sum of the absolute values of (p_j-n_j)\n",
    "print('','values : \\n ', func_list)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#solution :  [ 0.89819977  1.2252905  -0.18481207  0.30232177  0.59776286]\n",
    "# sum of the absolute values of the residuals :  8.68815436261272e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True solution : [0.7853981633974483, 1.1780972450961724, 0, 0, 0.7853981633974483]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residues :  [0.02729636688580301, 0.016092192472568267, 0.025683293530175524, 0.027296269101173068, 0.016092169177410777, 0.017271285036380705, 0.01727129048875934, 0.016092189463480032, 0.016092206423556847, 0.016092197534066585]\n",
      "\n",
      "5 min residues :  [0.016092169177410777, 0.016092189463480032, 0.016092192472568267, 0.016092197534066585, 0.016092206423556847]\n",
      "\n",
      " \n",
      " last trial info      message: `gtol` termination condition is satisfied.\n",
      "     success: True\n",
      "      status: 1\n",
      "         fun: [ 2.911e-03  2.219e-03 -3.379e-03  3.248e-04 -1.994e-03\n",
      "                2.888e-03  7.708e-04  6.942e-04 -9.125e-04]\n",
      "           x: [ 1.281e+00  8.534e-01  1.099e-01 -6.887e-03  9.731e-01]\n",
      "        cost: 1.9570409020647932e-05\n",
      "         jac: [[ 9.643e-02 -3.577e-02 ... -6.240e-04 -4.163e-02]\n",
      "               [-2.069e-02 -8.070e-02 ... -2.697e-04 -8.430e-04]\n",
      "               ...\n",
      "               [-6.621e-02 -2.177e-01 ... -5.950e-02  1.243e-01]\n",
      "               [ 1.563e-02  1.566e-02 ...  9.758e-02 -3.144e-02]]\n",
      "        grad: [ 9.234e-10  5.941e-10  5.100e-10 -1.734e-09 -1.077e-12]\n",
      "  optimality: 1.7337969980227677e-09\n",
      " active_mask: [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00]\n",
      "        nfev: 11\n",
      "        njev: 11\n",
      "\n",
      "true solution :  [0.7853981633974483, 1.1780972450961724, 0, 0, 0.7853981633974483]\n",
      "\n",
      "fidelities [0.7722857042305533, 0.8981966620139272]\n"
     ]
    }
   ],
   "source": [
    "# trying scipy least squares method\n",
    "from scipy.optimize import least_squares\n",
    "#creating loop over random initial guesses\n",
    "sol_list = []\n",
    "residue_list = []\n",
    "for i in range(10):\n",
    "    inv_guess = list(np.random.rand(5))\n",
    "    result = least_squares(eq_pr_num, inv_guess)\n",
    "    sol_list.append(result.x)\n",
    "    residue_list.append(sum([abs(i) for i in result.fun]))\n",
    "\n",
    "# print('solutions : ', sol_list)\n",
    "print('residues : ', residue_list)\n",
    "print('\\n5 min residues : ', sorted(residue_list)[:5])    # the 5 smallest residues\n",
    "print('\\n \\n last trial info', result)\n",
    "print('\\ntrue solution : ', [m.pi/4, m.pi/2-m.pi/8 , 0,0, m.pi/4])\n",
    "print('\\nfidelities', fn.fid(result.x, [m.pi/4, m.pi/2-m.pi/8 , 0,0, m.pi/4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# previous code for the loss function\\n# trying gradient descent method, but for the modified loss function. The new loss function is the absolute value of the difference between the probabilities and the counts\\n\\ndef loss_new(vars):                         \\n    # n_unnorm = [142, 128, 426, 2117, 1235, 1326, 2052, 1210, 1364]   # this is for params = [m.pi/4, m.pi/2-m.pi/8 , 0,0, m.pi/4]\\n    n_unnorm = [858, 820, 1701, 844, 794, 1616, 826, 825, 1716]     # this is for params = [0, m.pi/2, 0, 0, m.pi/4]\\n    \\n    n = [i/sum(n_unnorm) for i in n_unnorm]                          # normalise the counts\\n    eq_pr = [pr_num[i](*vars) for i in range(len(pr_num))]\\n    eq = [eq_pr[i] - n[i] for i in range(len(n))]\\n    loss = sum([abs(i) for i in eq])\\n    return loss\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# previous code for the loss function\n",
    "# trying gradient descent method, but for the modified loss function. The new loss function is the absolute value of the difference between the probabilities and the counts\n",
    "\n",
    "def loss_new(vars):                         \n",
    "    # n_unnorm = [142, 128, 426, 2117, 1235, 1326, 2052, 1210, 1364]   # this is for params = [m.pi/4, m.pi/2-m.pi/8 , 0,0, m.pi/4]\n",
    "    n_unnorm = [858, 820, 1701, 844, 794, 1616, 826, 825, 1716]     # this is for params = [0, m.pi/2, 0, 0, m.pi/4]\n",
    "    \n",
    "    n = [i/sum(n_unnorm) for i in n_unnorm]                          # normalise the counts\n",
    "    eq_pr = [pr_num[i](*vars) for i in range(len(pr_num))]\n",
    "    eq = [eq_pr[i] - n[i] for i in range(len(n))]\n",
    "    loss = sum([abs(i) for i in eq])\n",
    "    return loss\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#old loss\\ndef loss_old(vars, params_i = [0, m.pi/2, 0, 0, m.pi/4], N = 10000, nj_unnorm = None):                         \\n    if nj_unnorm != None:\\n        n_unnorm = nj_unnorm\\n    else:\\n        num_expt = fn.num_experiment(params= params_i, N = N)              # for getting the collapse count\\n        n_unnorm = num_expt[4]\\n\\n    n = [i/sum(n_unnorm) for i in n_unnorm]                          # normalise the counts\\n    eq_pr = [pr_num[i](*vars) for i in range(len(pr_num))]\\n    eq = [eq_pr[i] for i in range(len(n))]\\n    loss_old = sum([-i for i in eq])\\n    return loss_old\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#old loss\n",
    "def loss_old(vars, params_i = [0, m.pi/2, 0, 0, m.pi/4], N = 10000, nj_unnorm = None):                         \n",
    "    if nj_unnorm != None:\n",
    "        n_unnorm = nj_unnorm\n",
    "    else:\n",
    "        num_expt = fn.num_experiment(params= params_i, N = N)              # for getting the collapse count\n",
    "        n_unnorm = num_expt[4]\n",
    "\n",
    "    n = [i/sum(n_unnorm) for i in n_unnorm]                          # normalise the counts\n",
    "    eq_pr = [pr_num[i](*vars) for i in range(len(pr_num))]\n",
    "    eq = [eq_pr[i] for i in range(len(n))]\n",
    "    loss_old = sum([-i for i in eq])\n",
    "    return loss_old\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improving the previous loss function, new code: \n",
    "def loss_new(vars, params_tru = [0, m.pi/2, 0, 0, m.pi/4], N = 10000, nj_unnorm = None, lossfn = 'new'):                         \n",
    "    if nj_unnorm != None:\n",
    "        n_unnorm = nj_unnorm\n",
    "    else:\n",
    "        num_expt = fn.num_experiment(params= params_tru, N = N)                             # for getting the collapse count\n",
    "        n_unnorm = num_expt[4]\n",
    "\n",
    "    n = [i/sum(n_unnorm) for i in n_unnorm]                                                # normalise the counts\n",
    "    eq_pr = [pr_num[i](*vars) for i in range(len(pr_num))]\n",
    "    \n",
    "    # eq = [eq_pr[i] - n[i] for i in range(len(n))]                                        # method of equating from the log, the probs and the counts\n",
    "    lnl_p = [p * np.log(i) if i != 0 else 0 for i, p in zip(n, eq_pr)]                          # manually putting zero for cases of p_i*log(n_i) , if any n_i are 0.\n",
    "    lnl_n = [i * np.log(i) if i != 0 else 0 for i in n]                         \n",
    "    # eq = [n[i]*np.log(eq_pr[i]) - n[i]*np.log(n[i]) for i in range(len(n))]                # method of comparing the likelihood with the entropy/min likelihood\n",
    "    del_lnl = [(k-l) for k,l in zip(lnl_p, lnl_n)]\n",
    "    loss = sum([abs(i) for i in del_lnl])\n",
    "\n",
    "    if lossfn == 'old':\n",
    "        loss = sum([-(i) for i in lnl_p])\n",
    "    xx = 5\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result :    message: Desired error not necessarily achieved due to precision loss.\n",
      "  success: False\n",
      "   status: 2\n",
      "      fun: 1.4842637350202612\n",
      "        x: [ 6.854e-01  1.078e+00  0.000e+00  1.000e-01  1.185e+00]\n",
      "      nit: 0\n",
      "      jac: [ 4.938e+05  6.306e+05  1.514e+06  2.804e+06  2.617e+06]\n",
      " hess_inv: [[1 0 ... 0 0]\n",
      "            [0 1 ... 0 0]\n",
      "            ...\n",
      "            [0 0 ... 1 0]\n",
      "            [0 0 ... 0 1]]\n",
      "     nfev: 156\n",
      "     njev: 24\n",
      "  \n",
      " \n",
      " initial guess [0.6853981633974483, 1.0780972450961723, 0, 0.1, 1.1853981633974482]\n",
      " found solution :  [0.68539816 1.07809725 0.         0.1        1.18539816]\n",
      " true val [0.7853981633974483, 1.1780972450961724, 0, 0, 0.7853981633974483]\n",
      "fidelities [0.9900332889206207, 0.98856109647552]\n"
     ]
    }
   ],
   "source": [
    "# initial_guess = list(np.random.rand(5))\n",
    "inv_guess = [m.pi/4-.1, m.pi/2-m.pi/8-.1 , 0,.1, m.pi/4+ .4]    \n",
    "GD_res = GDlib(loss_new, inv_guess)\n",
    "print('result : ', GD_res)\n",
    "\n",
    "print('',' \\n \\n initial guess', inv_guess)\n",
    "print('','found solution : ', GD_res.x)\n",
    "print('','true val', [m.pi/4, m.pi/2-m.pi/8 , 0,0, m.pi/4])\n",
    "print('fidelities', fn.fid(GD_res.x, [m.pi/4, m.pi/2-m.pi/8 , 0,0, m.pi/4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hybride method seems to be working, when the new loss function is used instead of the old simple one. Exploring it further and after that creating graphs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: use inversion to get near, then run GDlib function. finally compare the fidelities.\n",
    "\n",
    "def Hybrid(params_i = [0, m.pi/2, 0, 0, m.pi/4], N = 10000, threshold = 'variable'):\n",
    "    inv = fn.Inversion(params = params_i, N = N, threshold = threshold)     # doing the inversion experiment\n",
    "    fid_inv = inv[0]\n",
    "    inv_params = inv[2]\n",
    "    initial_guess = inv_params          # initial guess for the grad descent is the final answer of the inversion method, which is already very close \n",
    "    \n",
    "    res_GD = GDlib(loss_new, initial_guess)   \n",
    "    opt_params = res_GD.x\n",
    "    fid = fn.fid(opt_params, params_i)          # fidelity of the final states with the sent states\n",
    "    \n",
    "    params_i_degrees =   [np.round(i*180/m.pi, 1) for i in params_i]\n",
    "    inv_params_degrees = [np.round(i*180/m.pi, 1) for i in inv_params]   \n",
    "    opt_params_degrees = [np.round(i*180/m.pi, 1) for i in opt_params]\n",
    "    \n",
    "    return fid\n",
    "\n",
    "\n",
    "# Hybrid()   # just to check if the function is working\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: use inversion to get near, then run GDlib function. finally compare the fidelities.\n",
    "\n",
    "def Hybrid(params_i = [0, m.pi/2, 0, 0, m.pi/4], N = 10000, threshold = 'variable'):\n",
    "    inv = fn.Inversion(params = params_i, N = N, threshold = threshold)     # doing the inversion experiment\n",
    "    fid_inv = inv[0]\n",
    "    inv_params = inv[2]\n",
    "    initial_guess = inv_params          # initial guess for the grad descent is the final answer of the inversion method, which is already very close \n",
    "    \n",
    "    res_GD = GDlib(loss_new, initial_guess, args = (params_i, N))\n",
    "    opt_params = res_GD.x\n",
    "    fid = fn.fid(opt_params, params_i)          # fidelity of the final states with the sent states\n",
    "    \n",
    "    params_i_degrees =   [np.round(i*180/m.pi, 3) for i in params_i]\n",
    "    inv_params_degrees = [np.round(i*180/m.pi, 3) for i in inv_params]   \n",
    "    opt_params_degrees = [np.round(i*180/m.pi, 3) for i in opt_params]\n",
    "    \n",
    "    return fid\n",
    "\n",
    "\n",
    "# Hybrid(params_i = [m.pi/8, m.pi/2-m.pi/8, 0, 0, m.pi/4], N = 10000, threshold = 'variable')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# writing a gradient descent function for the new loss function\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m\"\"\"def GD(params_i = [0,m.pi/2,0,0,m.pi/4], nit = 20, step = 1/120, show_calc = False):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m    grad_new = grad(vars = params_i, )\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m        print(value,'\\n ')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mreturn params_new\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m g \u001b[39m=\u001b[39m grad(\u001b[39mvars\u001b[39;49m \u001b[39m=\u001b[39;49m [\u001b[39m0.7497958771991733\u001b[39;49m, \u001b[39m0.9387189457887932\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m0.03129290610777863\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m3.135039348011299\u001b[39;49m, (\u001b[39m0.7039072158599036\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m3.0426163267295937e-18\u001b[39;49mj)], nj_unnorm \u001b[39m=\u001b[39;49m [\u001b[39m1323\u001b[39;49m, \u001b[39m754\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m1289\u001b[39;49m, \u001b[39m1311\u001b[39;49m, \u001b[39m1342\u001b[39;49m, \u001b[39m1321\u001b[39;49m, \u001b[39m1363\u001b[39;49m, \u001b[39m1297\u001b[39;49m], loss \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mnew\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb Cell 16\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     num_expt \u001b[39m=\u001b[39m fn\u001b[39m.\u001b[39mnum_experiment(params\u001b[39m=\u001b[39m params_i, N \u001b[39m=\u001b[39m N)              \u001b[39m# for getting the collapse count\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     n_unnorm \u001b[39m=\u001b[39m num_expt[\u001b[39m4\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m del_theta1 \u001b[39m=\u001b[39m loss_new(\u001b[39mvars\u001b[39;49m \u001b[39m=\u001b[39;49m [\u001b[39mvars\u001b[39;49m[\u001b[39m0\u001b[39;49m]\u001b[39m+\u001b[39;49ms,\u001b[39mvars\u001b[39;49m[\u001b[39m1\u001b[39;49m],\u001b[39mvars\u001b[39;49m[\u001b[39m2\u001b[39;49m],\u001b[39mvars\u001b[39;49m[\u001b[39m3\u001b[39;49m],\u001b[39mvars\u001b[39;49m[\u001b[39m4\u001b[39;49m]], nj_unnorm\u001b[39m=\u001b[39;49m nj_unnorm, lossfn \u001b[39m=\u001b[39;49m loss) \u001b[39m-\u001b[39m loss_new(\u001b[39mvars\u001b[39m \u001b[39m=\u001b[39m [\u001b[39mvars\u001b[39m[\u001b[39m0\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m1\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m2\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m3\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m4\u001b[39m]], nj_unnorm\u001b[39m=\u001b[39m nj_unnorm, lossfn \u001b[39m=\u001b[39m loss)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m del_theta2 \u001b[39m=\u001b[39m loss_new(\u001b[39mvars\u001b[39m \u001b[39m=\u001b[39m [\u001b[39mvars\u001b[39m[\u001b[39m0\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m1\u001b[39m]\u001b[39m+\u001b[39ms,\u001b[39mvars\u001b[39m[\u001b[39m2\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m3\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m4\u001b[39m]], nj_unnorm\u001b[39m=\u001b[39m nj_unnorm, lossfn \u001b[39m=\u001b[39m loss) \u001b[39m-\u001b[39m loss_new(\u001b[39mvars\u001b[39m \u001b[39m=\u001b[39m [\u001b[39mvars\u001b[39m[\u001b[39m0\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m1\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m2\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m3\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m4\u001b[39m]], nj_unnorm\u001b[39m=\u001b[39m nj_unnorm, lossfn \u001b[39m=\u001b[39m loss)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m del_phi1   \u001b[39m=\u001b[39m loss_new(\u001b[39mvars\u001b[39m \u001b[39m=\u001b[39m [\u001b[39mvars\u001b[39m[\u001b[39m0\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m1\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m2\u001b[39m]\u001b[39m+\u001b[39ms,\u001b[39mvars\u001b[39m[\u001b[39m3\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m4\u001b[39m]], nj_unnorm\u001b[39m=\u001b[39m nj_unnorm, lossfn \u001b[39m=\u001b[39m loss) \u001b[39m-\u001b[39m loss_new(\u001b[39mvars\u001b[39m \u001b[39m=\u001b[39m [\u001b[39mvars\u001b[39m[\u001b[39m0\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m1\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m2\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m3\u001b[39m],\u001b[39mvars\u001b[39m[\u001b[39m4\u001b[39m]], nj_unnorm\u001b[39m=\u001b[39m nj_unnorm, lossfn \u001b[39m=\u001b[39m loss)\n",
      "\u001b[1;32m/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mif\u001b[39;00m lossfn \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mold\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m([\u001b[39m-\u001b[39m(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m lnl_p])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m xx \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_nonlinear_eqn_method.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[39mif\u001b[39;00m info\u001b[39m.\u001b[39mpydev_state \u001b[39m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 988\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_wait_suspend(thread, frame, event, arg)\n\u001b[1;32m    989\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrace_dispatch\n\u001b[1;32m    990\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_wait_suspend\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mdo_wait_suspend(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#custom gradient descent algo, coz the scipy one doesnt converge\n",
    "def grad(vars, params_i = None ,nj_unnorm = None, s=(1/500), N = 10000, loss = 'new'):    # \"point\" is the list of parameters\n",
    "    if nj_unnorm != None:\n",
    "        n_unnorm = nj_unnorm\n",
    "    else:\n",
    "        num_expt = fn.num_experiment(params= params_i, N = N)              # for getting the collapse count\n",
    "        n_unnorm = num_expt[4]\n",
    "    \n",
    "    del_theta1 = loss_new(vars = [vars[0]+s,vars[1],vars[2],vars[3],vars[4]], nj_unnorm= nj_unnorm, lossfn = loss) - loss_new(vars = [vars[0],vars[1],vars[2],vars[3],vars[4]], nj_unnorm= nj_unnorm, lossfn = loss)\n",
    "    del_theta2 = loss_new(vars = [vars[0],vars[1]+s,vars[2],vars[3],vars[4]], nj_unnorm= nj_unnorm, lossfn = loss) - loss_new(vars = [vars[0],vars[1],vars[2],vars[3],vars[4]], nj_unnorm= nj_unnorm, lossfn = loss)\n",
    "    del_phi1   = loss_new(vars = [vars[0],vars[1],vars[2]+s,vars[3],vars[4]], nj_unnorm= nj_unnorm, lossfn = loss) - loss_new(vars = [vars[0],vars[1],vars[2],vars[3],vars[4]], nj_unnorm= nj_unnorm, lossfn = loss)\n",
    "    del_phi2   = loss_new(vars = [vars[0],vars[1],vars[2],vars[3]+s,vars[4]], nj_unnorm= nj_unnorm, lossfn = loss) - loss_new(vars = [vars[0],vars[1],vars[2],vars[3],vars[4]], nj_unnorm= nj_unnorm, lossfn = loss)\n",
    "    del_alpha  = loss_new(vars = [vars[0],vars[1],vars[2],vars[3],vars[4]+s], nj_unnorm= nj_unnorm, lossfn = loss) - loss_new(vars = [vars[0],vars[1],vars[2],vars[3],vars[4]], nj_unnorm= nj_unnorm, lossfn = loss)\n",
    "    \n",
    "    grad = [del_theta1/s,del_theta2/s,del_phi1/s,del_phi2/s,del_alpha/s]\n",
    "    grad = [i if abs(i) > 1e-10 else 0 for i in grad]\n",
    "    \n",
    "    xx = 5\n",
    "    return grad\n",
    "\n",
    "\n",
    "# writing a gradient descent function for the new loss function\n",
    "\n",
    "\"\"\"def GD(params_i = [0,m.pi/2,0,0,m.pi/4], nit = 20, step = 1/120, show_calc = False):\n",
    "    \n",
    "    grad_new = grad(vars = params_i, )\n",
    "    params_new = p\n",
    "    values = []\n",
    "    for i in range(nit):\n",
    "    grad_mod = (sum([abs(i)**2 for i in grad_new]))**(.5)\n",
    "    params_new = [params_new[i]-s*(grad_new[i]/grad_mod) for i in range(len(params_i))]\n",
    "    grad_new = grad(params_new)\n",
    "    value = [loss_new(params_new), params_new, grad_new, i]\n",
    "    values.append(value)\n",
    "    if i > (3/10)*nit//1 and i > 10:\n",
    "        s = 5*step\n",
    "        if i > (8/10)*nit//1:\n",
    "            s = 15*step\n",
    "    if show_calc == True:\n",
    "        print(value,'\\n ')\n",
    "return params_new\"\"\"\n",
    "\n",
    "g = grad(vars = [0.7497958771991733, 0.9387189457887932, -0.03129290610777863, -3.135039348011299, (0.7039072158599036-3.0426163267295937e-18j)], nj_unnorm = [1323, 754, 0, 1289, 1311, 1342, 1321, 1363, 1297], loss = 'new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true params :  [0.2617993877991494, 1.3089969389957472, 0, 0, 0.7853981633974483]\n",
      "opt1 :  [0.39144125708094557, 1.3393325856809397, 0.5964346298701403, 0.0840960428527506, 0.6244985013929705]\n",
      "fidelity :  [0.9528421705964317, 0.9986854880047514]\n"
     ]
    }
   ],
   "source": [
    "def GD_new(params_i, params_true = [0, m.pi/2, 0, 0, m.pi/4], nj_unnorm = None, nit = 20, step = 1/120, N = 10000, loss = 'new'):\n",
    "    # if nj_unnorm != None:                                                           # priority is using the given collapses, else build using fn.num_expt\n",
    "    #     nj_unnorm = nj_unnorm                                                                    \n",
    "    # else:\n",
    "    #     nj_unnorm = fn.num_experiment(params= params_true, N = N, an_pr= True)[4]           \n",
    "    if nj_unnorm == None:                                                           # priority is using the given collapses, else build using fn.num_expt\n",
    "        nj_unnorm = fn.num_experiment(params= params_true, N = N, an_pr= True)[4]           \n",
    "    params = params_i\n",
    "    loss_i = loss_new(vars = params, nj_unnorm= nj_unnorm)                                          # Initial parameters, loss\n",
    "    \n",
    "    params_history = [params]                                          # To store the history of parameters, loss and steps\n",
    "    loss_history = [loss_i]                                         \n",
    "    steps = [step]\n",
    "    for i in range(nit):\n",
    "        if loss == 'new':\n",
    "            gradients = grad(vars = params, nj_unnorm= nj_unnorm)\n",
    "        else:\n",
    "            gradients = grad(vars = params, nj_unnorm= nj_unnorm, loss = 'old')\n",
    "        params = [(i - step*grad) for i, grad in zip(params, gradients)]    # Basically, same as entry by entry updating the parameters.\n",
    "        \n",
    "        if i == (.5*nit)//1:                                   # variable step size after 50% and 75% of the iterations\n",
    "            step = step/2\n",
    "        if i == (.75*nit)//1:\n",
    "            step = step/5\n",
    "        steps.append(step)\n",
    "        params_history.append(params)\n",
    "        loss_history.append(loss_new(vars = params, nj_unnorm= nj_unnorm))\n",
    "        if sum(abs(m-n) for m,n in zip(params, params_history[-2])) < 1e-10:\n",
    "            print(f'Gradient descent converged at {params} after {i} iterations')\n",
    "    xx = 6                                                          # dummy for debugging\n",
    "    return params\n",
    "\n",
    "params_tru1 = [m.pi/12, m.pi/2-m.pi/12, 0, 0, m.pi/4]        # 60 degrees, symmetric in 1st quadramt\n",
    "# inv_guess = [0.2640432468429828, 1.3220290000177817, -0.09070684312662175, 0.0871477145803036, (0.7942549733540932)]\n",
    "\n",
    "opt_GD = GD_new( params_i = np.array(params_tru1)+ np.array([.2,-.1,.3,.1,-.2]), params_true= params_tru1, nit = 20, step = 1/2, N = 10000, loss = 'new')\n",
    "\n",
    "print('true params : ', params_tru1)\n",
    "print('opt1 : ', opt_GD)\n",
    "print('fidelity : ', fn.fid(opt_GD, params_tru1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999923064378412, 0.9999739958697293]\n",
      "[0.002773730680720482, 1.5758957734000354, 0.07982622120976857, 0.2738479925024069, 0.7828944726658738]\n",
      "[0, 1.5707963267948966, 0, 0, 0.7853981633974483]\n"
     ]
    }
   ],
   "source": [
    "# opt1 = GD_new([.2, m.pi/2+.3, .1, .3, m.pi/4+.2], nit = 30, step = 1/50, N = 10000)\n",
    "opt_GD = GD_new([.2, m.pi/2+.3, .1, .3, m.pi/4+.2], [0, m.pi/2, 0,0,m.pi/4 ], nit = 30, step = 1/50, N = 10000)\n",
    "\n",
    "print(fn.fid(opt_GD, [0, m.pi/2, 0, 0, m.pi/4]))\n",
    "\n",
    "print(opt_GD)\n",
    "print([0, m.pi/2, 0, 0, m.pi/4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************\n",
      "opt1 : [0.3924635740902881, 1.1593026216706654, 0.09321136790956905, -0.01055517992478513, 0.7970449854139229] \n",
      " tru: [0.39269908169872414, 1.1780972450961724, 0, 0, 0.7853981633974483] \n",
      " inv_opt1 : [0.42894315024735835, 1.205053566080319, -0.10281952589940356, -0.06935898188890478, (0.7393841575881271-1.3161585254031097e-17j)] \n",
      " fid : [0.9989151970427949, 0.9996323638518374] \n",
      " inv_fid : [0.9972744682446901, 0.9987057043660503]\n"
     ]
    }
   ],
   "source": [
    "# the new GD works. Trying more examples, comparing with the inversion method results\n",
    "#MAIN RESULTS\n",
    "params_tru1 = [m.pi/8, m.pi/2-m.pi/8, 0, 0, m.pi/4]        # 45 degrees, symmetric in 1st quadramt\n",
    "a = [rand.uniform(0,m.pi/2) for i in range(5)]\n",
    "\n",
    "\n",
    "opt_GD = GD_new( params_i = np.array(params_tru1)+ np.array([.2,-.1,.3,.1,-.2]), params_true= [m.pi/8, m.pi/2-m.pi/8, 0, 0, m.pi/4], nit = 100, step = 1/70, N = 10000)\n",
    "inv = fn.Inversion_new(params = params_tru1, N = 10000, threshold = 'variable')\n",
    "opt_inv = inv[2]\n",
    "fid_inv = inv[0]\n",
    "\n",
    "print('**************')\n",
    "print(f'opt1 : {opt_GD} \\n tru: {params_tru1} \\n inv_opt1 : {opt_inv} \\n fid : {fn.fid(opt_GD, params_tru1)} \\n inv_fid : {fid_inv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************\n",
      "opt1 : [0.8307122743238626, 2.2649587870653263, 0.2289091344452977, 0.10277245437261867, 0.24262332055383792] \n",
      " tru: [0.7853981633974483, 2.356194490192345, 0, 0, 0.7853981633974483] \n",
      " inv_opt1 : [0.764968395048091, 0.9210267917186483, 0.0074979798787395, -3.1147480592765593, (0.7130394459296733-1.9306544924011948e-18j)] \n",
      " fid : [0.9849588171152427, 0.9891046950479263] \n",
      " inv_fid : [0.9995686395003334, 0.9815438323155526]\n"
     ]
    }
   ],
   "source": [
    "params_tru1 = [m.pi/4, m.pi/2+m.pi/4, 0, 0, m.pi/4]        # 45 degrees around +y axis\n",
    "\n",
    "opt_GD = GD_new( params_i = np.array(params_tru1)+ np.array([.2,-.1,.3,.1,-.2]), params_true= [m.pi/8, m.pi/2-m.pi/8, 0, 0, m.pi/4], nit = 150, step = 1/150, N = 10000)\n",
    "inv = fn.Inversion_new(params = params_tru1, N = 10000, threshold = 'variable')\n",
    "opt_inv = inv[2]\n",
    "fid_inv = inv[0]\n",
    "\n",
    "print('**************')\n",
    "print(f'opt1 : {opt_GD} \\n tru: {params_tru1} \\n inv_opt1 : {opt_inv} \\n fid : {fn.fid(opt_GD, params_tru1)} \\n inv_fid : {fid_inv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************\n",
      "opt1 : [0.7332149883677442, 2.2453262257391087, 0.1751708024020456, 0.09599787964324194, 0.20357026537777298] \n",
      " tru: [0.7853981633974483, 2.356194490192345, 0, 0, 0.39269908169872414] \n",
      " inv_opt1 : [0.795722429049192, 0.9515225785338458, 0.013511744947243418, -3.101715467918529, (0.35114419683630715-8.704203544984617e-18j)] \n",
      " fid : [0.9896694144220264, 0.9855127415703802] \n",
      " inv_fid : [0.9998477819368514, 0.9722798607902248]\n"
     ]
    }
   ],
   "source": [
    "params_tru1 = [m.pi/4, m.pi/2+m.pi/4, 0, 0, m.pi/8]     # smaller alpha\n",
    "\n",
    "\n",
    "opt_GD = GD_new( params_i = np.array(params_tru1)+ np.array([.2,-.1,.3,.1,-.2]), params_true= [m.pi/8, m.pi/2-m.pi/8, 0, 0, m.pi/4], nit = 100, step = 1/30, N = 10000)\n",
    "inv = fn.Inversion_new(params = params_tru1, N = 10000, threshold = 'variable')\n",
    "opt_inv = inv[2]\n",
    "fid_inv = inv[0]\n",
    "\n",
    "print('**************')\n",
    "print(f'opt1 : {opt_GD} \\n tru: {params_tru1} \\n inv_opt1 : {opt_inv} \\n fid : {fn.fid(opt_GD, params_tru1)} \\n inv_fid : {fid_inv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************\n",
      "\n",
      " opt1 : [0.3637451682143003, 1.1848520808896752, 0.022800422273176593, 0.005606011675520266, 0.8049902701566931] \n",
      " tru: [0.2617993877991494, 1.3089969389957472, 0, 0, 0.7853981633974483] \n",
      " inv_opt1 : [0.27718954079343294, 1.3165191283194537, 0.04485633761689563, -0.05807442691937226, (0.7742191390949461+5.930828419406237e-18j)] \n",
      " fid : [0.9895998011561535, 0.9846643276821502] \n",
      " inv_fid : [0.999630784606342, 0.9997382018126175]\n",
      "\n",
      "**************\n"
     ]
    }
   ],
   "source": [
    "params_tru1 = [m.pi/12, m.pi/2-m.pi/12, 0, 0, m.pi/4]        # 60 degrees, symmetric in 1st quadramt\n",
    "# inv_guess = [0.2640432468429828, 1.3220290000177817, -0.09070684312662175, 0.0871477145803036, (0.7942549733540932)]\n",
    "\n",
    "opt_GD = GD_new( params_i = np.array(params_tru1)+ np.array([.2,-.1,.3,.1,-.2]), params_true= [m.pi/8, m.pi/2-m.pi/8, 0, 0, m.pi/4], nit = 1000, step = 1/10, N = 10000, loss = 'new')\n",
    "# opt1 = GD_new( params_i = inv_guess , params_true= [m.pi/8, m.pi/2-m.pi/8, 0, 0, m.pi/4], nit = 5, step = 1/100, N = 10000)\n",
    "inv = fn.Inversion_new(params = params_tru1, N = 10000, threshold = 'variable')\n",
    "opt_inv = inv[2]\n",
    "fid_inv = inv[0]\n",
    "\n",
    "print('**************')\n",
    "print(f'\\n opt1 : {opt_GD} \\n tru: {params_tru1} \\n inv_opt1 : {opt_inv} \\n fid : {fn.fid(opt_GD, params_tru1)} \\n inv_fid : {fid_inv}')\n",
    "print('\\n**************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_tru1 = [m.pi/12, m.pi/2-m.pi/12, 0, 0, m.pi/4]        # 60 degrees, symmetric in 1st quadramt\n",
    "# inv_guess = [0.2640432468429828, 1.3220290000177817, -0.09070684312662175, 0.0871477145803036, (0.7942549733540932)]\n",
    "\n",
    "opt_GD = GD_new( params_i = np.array(params_tru1)+ np.array([.2,-.1,.3,.1,-.2]), params_true= [m.pi/8, m.pi/2-m.pi/8, 0, 0, m.pi/4], nit = 10, step = 1/10, N = 10000, loss = 'new')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#rough\\nparams_tru1 = [m.pi/12, m.pi/2-m.pi/12, 0, 0, m.pi/4]  \\nres = GDlib(loss_new, np.array(params_tru1)+ np.array([.2,-.1,.3,.1,-.2]), args = (params_tru1, 10000, None, 'new'), method='Nelder-Mead')\\nprint(res)\\n\\n#fidelities\\nfid= fn.fid(res.x, params_tru1)\\nprint('fid',fid)\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#rough\n",
    "params_tru1 = [m.pi/12, m.pi/2-m.pi/12, 0, 0, m.pi/4]  \n",
    "res = GDlib(loss_new, np.array(params_tru1)+ np.array([.2,-.1,.3,.1,-.2]), args = (params_tru1, 10000, None, 'new'), method='Nelder-Mead')\n",
    "print(res)\n",
    "\n",
    "#fidelities\n",
    "fid= fn.fid(res.x, params_tru1)\n",
    "print('fid',fid)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating table of results. Comparing the results of the inversion method and the gradient descent method (using the new loss function)\n",
    "\n",
    "# true value = [m.pi/8, m.pi/2-m.pi/8, 0, 0, m.pi/4]\n",
    "params_tru = [m.pi/8, m.pi/2-m.pi/8, 0, 0, m.pi/4]\n",
    "\n",
    "def results(params_tru, nit = 100, step = 1/70, N = 10000):\n",
    "    inv = fn.Inversion_new(params = params_tru, N = N, threshold = 'variable')\n",
    "    nj_unnorm = inv[6]\n",
    "    opt_inv = inv[2]\n",
    "    # inv_fid_c = inv[0]                              # using coeffcients from the inversion protocol to calculate fidelity\n",
    "    fid_inv = fn.fid(opt_inv, params_tru)        # using parameters to calculate fidelity, should be same as from the coefficients\n",
    "    \n",
    "    opt_GD = GD_new( params_i = opt_inv , nj_unnorm = nj_unnorm, nit = nit, step = step, N = N)\n",
    "    fid_opt = fn.fid(opt_GD, params_tru)\n",
    "    \n",
    "    ppm_inv_fid = [(1- i)*1e6 for i in fid_inv]     # parts per million error in fids\n",
    "    ppm_opt_fid = [(1- i)*1e6 for i in fid_opt]\n",
    "    print(f'tru_params_deg: {[i*(180/m.pi) for i in params_tru]} \\n tru_params: {params_tru} \\n opt_inv: {opt_inv} \\n opt_GD: {opt_GD} \\n \\n  inv_fid: {fid_inv} \\n GD_fid: {fid_opt}  \\n\\n ppm_inv_fid: {ppm_inv_fid} \\n ppm_opt_fid: {ppm_opt_fid} \\n')\n",
    "\n",
    "    return [params_tru, opt_inv, opt_GD , fid_inv, fid_opt]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples for sending to prof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tru_params_deg: [14.999999999999998, 75.0, 0.0, 0.0, 45.0] \n",
      " tru_params: [0.2617993877991494, 1.3089969389957472, 0, 0, 0.7853981633974483] \n",
      " opt_inv: [0.26822093903074223, 1.3152268580213222, -0.0998557951966819, -0.07997179870362393, (0.7855608729803474+1.5907079090525755e-18j)] \n",
      " opt_GD: [0.24276559152604382, 1.3133280465128043, -0.06366771380786686, -0.039137620112997054, (0.7885650955912604+1.5907079090525755e-18j)] \n",
      " \n",
      "  inv_fid: [0.9993222834226456, 0.999570336096648] \n",
      " GD_fid: [0.9994013736571075, 0.9998869589965258]  \n",
      "\n",
      " ppm_inv_fid: [677.7165773543813, 429.6639033519734] \n",
      " ppm_opt_fid: [598.6263428925387, 113.04100347420132] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.2617993877991494, 1.3089969389957472, 0, 0, 0.7853981633974483],\n",
       " [0.26822093903074223,\n",
       "  1.3152268580213222,\n",
       "  -0.0998557951966819,\n",
       "  -0.07997179870362393,\n",
       "  (0.7855608729803474+1.5907079090525755e-18j)],\n",
       " [0.24276559152604382,\n",
       "  1.3133280465128043,\n",
       "  -0.06366771380786686,\n",
       "  -0.039137620112997054,\n",
       "  (0.7885650955912604+1.5907079090525755e-18j)],\n",
       " [0.9993222834226456, 0.999570336096648],\n",
       " [0.9994013736571075, 0.9998869589965258]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_tru1 = [m.pi/12, m.pi/2-m.pi/12, 0, 0, m.pi/4]   # 60 degrees, symmetric in 1st quadrant\n",
    "\n",
    "results(params_tru1, nit = 200, step = 1/10, N = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tru_params_deg: [45.0, 135.0, 0.0, 0.0, 45.0] \n",
      " tru_params: [0.7853981633974483, 2.356194490192345, 0, 0, 0.7853981633974483] \n",
      " opt_inv: [0.760436241312643, 0.9225742255817486, -0.029157606400135486, 3.122604226403839, (0.7173023200024781-3.260824506144435e-18j)] \n",
      " opt_GD: [0.7782118509303689, 0.8149008493385945, 0.028610590468963373, 3.1921349506973336, (0.7753834437750255-3.260824506144435e-18j)] \n",
      " \n",
      "  inv_fid: [0.9991647702011369, 0.9812136958082733] \n",
      " GD_fid: [0.9997437514242019, 0.9984924601994433]  \n",
      "\n",
      " ppm_inv_fid: [835.2297988630797, 18786.304191726667] \n",
      " ppm_opt_fid: [256.24857579809037, 1507.5398005567342] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.7853981633974483, 2.356194490192345, 0, 0, 0.7853981633974483],\n",
       " [0.760436241312643,\n",
       "  0.9225742255817486,\n",
       "  -0.029157606400135486,\n",
       "  3.122604226403839,\n",
       "  (0.7173023200024781-3.260824506144435e-18j)],\n",
       " [0.7782118509303689,\n",
       "  0.8149008493385945,\n",
       "  0.028610590468963373,\n",
       "  3.1921349506973336,\n",
       "  (0.7753834437750255-3.260824506144435e-18j)],\n",
       " [0.9991647702011369, 0.9812136958082733],\n",
       " [0.9997437514242019, 0.9984924601994433]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_tru1 = [m.pi/4, m.pi/2+m.pi/4, 0, 0, m.pi/4]   # 90 degrees, symmetric to +y axis\n",
    "\n",
    "results(params_tru1, nit = 100, step = 1/4, N = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tru_params_deg: [29.999999999999996, 119.99999999999999, 0.0, 0.0, 45.0] \n",
      " tru_params: [0.5235987755982988, 2.0943951023931953, 0, 0, 0.7853981633974483] \n",
      " opt_inv: [0.5466839134667312, 1.1137474542780048, -0.02610471231505182, -3.113696061516407, (0.7600429759468649+6.383284426249612e-20j)] \n",
      " opt_GD: [0.5412658612637588, 1.0668487939934668, -0.011217062705440345, -3.0935770884404192, (0.7748952389521798+6.383284426249612e-20j)] \n",
      " \n",
      "  inv_fid: [0.9993361369138606, 0.9954442077978668] \n",
      " GD_fid: [0.99966384864141, 0.9991918195432765]  \n",
      "\n",
      " ppm_inv_fid: [663.8630861394157, 4555.792202133202] \n",
      " ppm_opt_fid: [336.1513585899978, 808.180456723484] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.5235987755982988, 2.0943951023931953, 0, 0, 0.7853981633974483],\n",
       " [0.5466839134667312,\n",
       "  1.1137474542780048,\n",
       "  -0.02610471231505182,\n",
       "  -3.113696061516407,\n",
       "  (0.7600429759468649+6.383284426249612e-20j)],\n",
       " [0.5412658612637588,\n",
       "  1.0668487939934668,\n",
       "  -0.011217062705440345,\n",
       "  -3.0935770884404192,\n",
       "  (0.7748952389521798+6.383284426249612e-20j)],\n",
       " [0.9993361369138606, 0.9954442077978668],\n",
       " [0.99966384864141, 0.9991918195432765]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90 deg : (30, 120 deg)\n",
    "params_tru1 = [m.pi/6, m.pi/2+m.pi/6, 0, 0, m.pi/4]   \n",
    "\n",
    "results(params_tru1, nit = 1000, step = 1/20, N = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tru_params_deg: [29.999999999999996, 119.99999999999999, 0.0, 0.0, 29.999999999999996] \n",
      " tru_params: [0.5235987755982988, 2.0943951023931953, 0, 0, 0.5235987755982988] \n",
      " opt_inv: [0.520485416640111, 1.1118719934403491, 0.048973286483934945, -3.068867696543849, (0.4867482799867063+4.152601949231743e-18j)] \n",
      " opt_GD: [0.5099336325957732, 1.067218082434157, 0.02826232632797275, -3.141224862932065, (0.5142003694927895+4.152601949231743e-18j)] \n",
      " \n",
      "  inv_fid: [0.9995423251671268, 0.9949139092924759] \n",
      " GD_fid: [0.9996659368054794, 0.9995992071221663]  \n",
      "\n",
      " ppm_inv_fid: [457.67483287317833, 5086.090707524082] \n",
      " ppm_opt_fid: [334.06319452056186, 400.7928778336778] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.5235987755982988, 2.0943951023931953, 0, 0, 0.5235987755982988],\n",
       " [0.520485416640111,\n",
       "  1.1118719934403491,\n",
       "  0.048973286483934945,\n",
       "  -3.068867696543849,\n",
       "  (0.4867482799867063+4.152601949231743e-18j)],\n",
       " [0.5099336325957732,\n",
       "  1.067218082434157,\n",
       "  0.02826232632797275,\n",
       "  -3.141224862932065,\n",
       "  (0.5142003694927895+4.152601949231743e-18j)],\n",
       " [0.9995423251671268, 0.9949139092924759],\n",
       " [0.9996659368054794, 0.9995992071221663]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90 deg : (30, 120 deg); this time smaller alpha\n",
    "params_tru1 = [m.pi/6, m.pi/2+m.pi/6, 0, 0, m.pi/6]\n",
    "\n",
    "results(params_tru1, nit = 200, step = 1/10, N = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tru_params_deg: [29.999999999999996, 119.99999999999999, 45.0, 90.0, 29.999999999999996] \n",
      " tru_params: [0.5235987755982988, 2.0943951023931953, 0.7853981633974483, 1.5707963267948966, 0.5235987755982988] \n",
      " opt_inv: [0.4682041048878335, 1.3693299151594398, 0.7692265173690841, -0.3528863562497126, (0.6232648008274801-1.6179898358444556e-17j)] \n",
      " opt_GD: [0.48487692940446503, 1.1092739184859342, 0.8092943259889571, -1.307371119859963, (0.5930335042277685-1.6179898358444556e-17j)] \n",
      " \n",
      "  inv_fid: [0.9968889642026643, 0.7886601858599687] \n",
      " GD_fid: [0.9983994085677436, 0.9842398242673239]  \n",
      "\n",
      " ppm_inv_fid: [3111.0357973357372, 211339.81414003135] \n",
      " ppm_opt_fid: [1600.5914322564374, 15760.175732676074] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.5235987755982988,\n",
       "  2.0943951023931953,\n",
       "  0.7853981633974483,\n",
       "  1.5707963267948966,\n",
       "  0.5235987755982988],\n",
       " [0.4682041048878335,\n",
       "  1.3693299151594398,\n",
       "  0.7692265173690841,\n",
       "  -0.3528863562497126,\n",
       "  (0.6232648008274801-1.6179898358444556e-17j)],\n",
       " [0.48487692940446503,\n",
       "  1.1092739184859342,\n",
       "  0.8092943259889571,\n",
       "  -1.307371119859963,\n",
       "  (0.5930335042277685-1.6179898358444556e-17j)],\n",
       " [0.9968889642026643, 0.7886601858599687],\n",
       " [0.9983994085677436, 0.9842398242673239]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90 deg : (30, 120 deg). smaller alpha AND random phi angles.\n",
    "params_tru1 = [m.pi/6, m.pi/2+m.pi/6, m.pi/4, m.pi/2, m.pi/6]\n",
    "results(params_tru1, nit = 500, step = 1/10, N = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
