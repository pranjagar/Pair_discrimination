{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import sympy as sym\n",
    "import scipy as sci\n",
    "import matplotlib.ticker as ticker\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import cmath as cm\n",
    "from IPython.display import display, Latex\n",
    "from sympy import pprint\n",
    "from scipy.optimize import minimize as GDlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1, theta2, phi1, phi2, alpha = sym.symbols('theta1 theta2 phi1 phi2 alpha')\n",
    "c1, c2, s1, s2, w1, w2 = sym.cos(theta1), sym.cos(theta2), sym.sin(theta1), sym.sin(theta2), sym.cos(alpha)**2, sym.sin(alpha)**2\n",
    "\n",
    "def Creating_states( params = [0, m.pi/2,0, 0, m.pi/4], input_type = 'theta', Abstract = False):    # coeff list like [a0,a1,b0,b1]\n",
    "    a0, a1 = sym.cos(theta1), sym.exp(sym.I*phi1)*sym.sin(theta1)\n",
    "    b0, b1 = sym.cos(theta2), sym.exp(sym.I*phi2)*sym.sin(theta2)\n",
    "    alpha = sym.symbols('alpha')        # Doesn't work without it for some reason..\n",
    "    if Abstract == False:\n",
    "        alpha = params[4] \n",
    "        a0, a1, b0, b1 = a0.subs({theta1 : params[0]}), a1.subs({theta1 : params[0], phi1 : params[2]}), b0.subs({theta2 : params[1]}), b1.subs({theta2 : params[1], phi2: params[3]})\n",
    "        alpha = params[4] \n",
    "        coeff_raw = [a0,a1, b0, b1]\n",
    "        coeff = [i if abs(i)> 1e-9 else 0 for i in coeff_raw]\n",
    "        a0, a1, b0, b1 = coeff[0],coeff[1],coeff[2],coeff[3]\n",
    "    psi0, psi1 = sym.Matrix([a0,a1]), sym.Matrix([b0,b1])      # defining states\n",
    "    \n",
    "    psi0psi0_list, psi1psi1_list = [psi0[0]*psi0[0], psi0[1]*psi0[1], (np.sqrt(2)*psi0[0]*psi0[1]) ],  [psi1[0]*psi1[0],psi1[1]*psi1[1], (np.sqrt(2)*psi1[0]*psi1[1])] # @@@ the square rooting is simplistic. see notebook for better\n",
    "    # note the order is now how prof Hillery is using ie. [|00>, |11>, |+>] (instead of the previous order [|00>, |+>, |11> ])\n",
    "    psi0psi0, psi1psi1 = sym.Matrix(psi0psi0_list), sym.Matrix(psi1psi1_list)\n",
    "    rho = sym.cos(alpha)**2*(psi0psi0*psi0psi0.T)+ sym.sin(alpha)**2*(psi1psi1*psi1psi1.T)\n",
    "    return([[psi0,psi1], [psi0psi0,psi1psi1], rho])\n",
    "\n",
    "# # analytic formuale for the probabilities, as given in the notes\n",
    "pr1 = (1/6)*(w1*s1**2*(1+c1**2 -2*m.sqrt(2)*sym.cos(phi1)*s1*c1)+w2*s2**2*(1+c2**2-2*m.sqrt(2)*sym.cos(phi2)*s2*c2))\n",
    "pr2 = (1/6)*(w1*c1**2*(1+s1**2 -2*m.sqrt(2)*sym.cos(phi1)*c1*s1) + w2*c2**2*(1+s2**2*-2*m.sqrt(2)*sym.cos(phi2)*c2*s2))\n",
    "pr3 = (1/6)*(w1*(c1**4+s1**4 -2*sym.cos(2*phi1)*s1**2*c1**2)+ w2*(c2**4+ s2**4 - 2*sym.cos(2*phi2)*s2**2*c2**2))\n",
    "pr4 = (1/6)*(w1*s1**2*(1+c1**2 -2*m.sqrt(2)*sym.cos(phi1+2*m.pi/3)*s1*c1)+ w2*s2**2*(1+c2**2-2*m.sqrt(2)*sym.cos(phi2+2*m.pi/3)*s2*c2))\n",
    "pr5= (1/6)*(w1*c1**2*(1+s1**2 -2*m.sqrt(2)*sym.cos(phi1-2*m.pi/3)*c1*s1)+ w2*c2**2*(1+s2**2-2*m.sqrt(2)*sym.cos(phi2-2*m.pi/3)*c2*s2))\n",
    "pr6 = (1/6)*(w1*(c1**4+s1**4-2*sym.cos(2*phi1 - 2*m.pi/3)*c1**2*s1**2)+ w2*(c2**4+s2**4-2*sym.cos(2*phi2 - 2*m.pi/3)*c2**2*s2**2))\n",
    "pr7 = (1/6)*(w1*s1**2*(1+c1**2-2*m.sqrt(2)*sym.cos(phi1-2*m.pi/3)*s1*c1)+ w2*s2**2*(1+c2**2-2*m.sqrt(2)*sym.cos(phi2-2*m.pi/3)*s2*c2))\n",
    "pr8 = (1/6)*(w1*c1**2*(1+s1**2-2*m.sqrt(2)*sym.cos(phi1-2*m.pi/3)*c1*s1)+ w2*c2**2*(1+s2**2-2*m.sqrt(2)*sym.cos(phi2-2*m.pi/3)*c2*s2))\n",
    "pr9 = (1/6)*(w1*(c1**4+s1**4-2*sym.cos(2*phi1+2*m.pi/3)*c1**2*s1**2)+ w2*(c2**4+s2**4-2*sym.cos(2*phi2+2*m.pi/3)*c2**2*s2**2))\n",
    "pr = [pr1, pr2,pr3, pr4,pr5, pr6,pr7, pr8,pr9]      # list of analytic prob.\n",
    "\n",
    "w = m.e**((2/3)*m.pi*(1j))     # third root of unity\n",
    "POVM_vec = (1/(2**.5))*(np.array([[0,1,-1],[-1,0,1],[1,-1,0],[0,w,-w**2],[-1,0,w**2],[1,-w,0],[0,w**2,-w],[-1,0,w],[1,-w**2,0]]))  # an array of POVM direction vectors\n",
    "POVM_elts = [(1/3)*np.outer(np.conjugate(POVM_vec[i]),POVM_vec[i]) for i in range(len(POVM_vec))]   # a list of POVM matrices\n",
    "\n",
    "def num_experiment(N = 10000, params = [0,m.pi/2,0,0,m.pi/4], show_calcs = False):\n",
    "    creation = Creating_states( params = params, Abstract = 0) # theoretical rho\n",
    "    states = creation[0]\n",
    "    rho = creation[-1]\n",
    "    # print(rho)\n",
    "    # print(states)\n",
    "    prob_vec_sympy =  [np.trace(np.dot(POVM_elts[i],rho)) for i in range(9)]    # created list of Th probabilities\n",
    "    prob_vec_raw = [(float(i.as_real_imag()[0])+float(i.as_real_imag()[1])*1j) for i in prob_vec_sympy]  # this is to avoid error, to convert sympy float to ordinary number\n",
    "    prob_vec = [round(i.real, 10) for i in prob_vec_raw if abs(i.imag) < .0001]          # cleaned up theoretical prob vector\n",
    "\n",
    "    POVM_dir_symbols = ['d1','d2','d3','d4','d5','d6','d7','d8','d9']      # symbols to indicate collapsed direction\n",
    "    #prob distribution is simply the corresponding elements of the prob_vec\n",
    "    collapse_dir_vec = rand.choices(POVM_dir_symbols, weights=prob_vec, k = N)   # choosing collapse directions with weights for N trials\n",
    "    nj_vec = [collapse_dir_vec.count(f'd{i+1}') for i in range(9)]\n",
    "    pj_num_vec = [i/N for i in nj_vec]                                  # numerical prob vector     \n",
    "\n",
    "    if show_calcs == True: \n",
    "        print(\"\\n rho \\n\", rho)\n",
    "        print(\"\\n prob vec\", prob_vec)\n",
    "        print(\"\\n nj vec\",nj_vec)\n",
    "        print(\"\\n sum pj, sum nj \", sum(prob_vec), sum(nj_vec))\n",
    "    return [states, rho, prob_vec, nj_vec]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(([i/sum(num_experiment()[-1]) for i in num_experiment()[-1]]) ) # Numerical probabilities\\nprint(num_experiment()[-2] )       # th prob\\n\\nprint([i.subs({theta1: 0, theta2: m.pi/2, phi1:0, phi2:0, alpha: m.pi/4}) for i in pr] )   # analytical probabilities\\nabs_k = [np.trace(np.outer(Creating_states(Abstract=1)[-1], POVM_elts[i])) for i in range(len(POVM_elts))]\\nprint([i.subs({theta1: 0, theta2: m.pi/2, phi1:0, phi2:0, alpha: m.pi/4}) for i in abs_k] )   # sympy analytical prob\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rough\n",
    "\"\"\"print(([i/sum(num_experiment()[-1]) for i in num_experiment()[-1]]) ) # Numerical probabilities\n",
    "print(num_experiment()[-2] )       # th prob\n",
    "\n",
    "print([i.subs({theta1: 0, theta2: m.pi/2, phi1:0, phi2:0, alpha: m.pi/4}) for i in pr] )   # analytical probabilities\n",
    "abs_k = [np.trace(np.outer(Creating_states(Abstract=1)[-1], POVM_elts[i])) for i in range(len(POVM_elts))]\n",
    "print([i.subs({theta1: 0, theta2: m.pi/2, phi1:0, phi2:0, alpha: m.pi/4}) for i in abs_k] )   # sympy analytical prob\n",
    "\"\"\"\n",
    "# [0.0807, 0.0806, 0.1698, 0.0828, 0.0863, 0.1653, 0.0834, 0.0806, 0.1705]\n",
    "# [0.0833, 0.0833, 0.1666, 0.0833, 0.0833, 0.1666, 0.0833, 0.0833, 0.166]\n",
    "# [0.0833, 0.08333, 0.166, 0.0833, 0.0833, 0.166, 0.0833, 0.0833, 0.1666]\n",
    "# [0.0833, 0.08333, 0.1667, 0.0833, 0.0833, 0.166, 0.0833, 0.0833, 0.166]\n",
    "\n",
    "# Verified that Probabilities are matching from all Four methods : Analytical, sympy Analytical, Th num, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logL(params = [0,m.pi/2,0,0,m.pi/4], N = 10000, show_calcs = False):\n",
    "    num_expt = num_experiment(params = params, N = N)\n",
    "    states = num_expt[0]\n",
    "    rho = num_expt[1]\n",
    "    th_pj_vec = num_expt[2]\n",
    "    nj_vec = num_expt[3]\n",
    "    \n",
    "    lnL_list = [nj_vec[i]*sym.log(pr[i]) for i in range(len(pr))]\n",
    "    lnL = sum(lnL_list)         # created the likelihood fucntion\n",
    "    # lnL_psuedo = sum([n[i]*m.log(n_normalized[i]) for i in range(len(n))])\n",
    "\n",
    "    # global lnL\n",
    "    logL = lnL.subs({theta1: params[0], theta2: params[1], phi1: params[2] , phi2: params[3] , alpha: params[4]})\n",
    "\n",
    "    if logL < -500000:\n",
    "        print(logL, params)\n",
    "\n",
    "    return (-logL.evalf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 23098.9783021071\n",
       "        x: [ 1.000e+00  3.159e+00 -1.215e+00 -1.553e+00  3.159e+00]\n",
       "      nit: 6\n",
       "      jac: [-1.771e+04  1.670e-01  2.183e-03  2.183e-03 -9.329e+01]\n",
       "     nfev: 66\n",
       "     njev: 11\n",
       " hess_inv: <5x5 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rough\n",
    "params0 = [.1, .3, 0, 0, m.pi/4]\n",
    "nj_vec = [1678, 0, 1639, 1656, 0, 1662, 1723, 0, 1642]\n",
    "bounds = [(-1,1), (-m.pi/2+m.pi/180,m.pi+m.pi/180),(-m.pi/2+m.pi/180,m.pi+m.pi/180),(-m.pi/2+m.pi/180,m.pi+m.pi/180),(-m.pi/2+m.pi/180,m.pi+m.pi/180)]\n",
    "print(sum(nj_vec))\n",
    "def lnL2(search_params = params0):\n",
    "        global nj_vec                                     # Importing the collapse counts From the outer function\n",
    "        global pr                                           # importing the Analytical probabilities\n",
    "        lnL_list = [nj_vec[i]*sym.log(pr[i]) for i in range(len(pr))]        \n",
    "        lnL_abst = sum(lnL_list).evalf()                                  # created the likelihood fucntion\n",
    "        lnL = lnL_abst.subs({theta1: search_params[0], theta2: search_params[1] , phi1: search_params[2] , phi2: search_params[3] , alpha: search_params[4] })\n",
    "        return -(lnL.evalf())\n",
    "\n",
    "opt = GDlib(lnL2, params0, bounds= bounds)\n",
    "opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography main March17.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [opt\u001b[39m.\u001b[39msuccess,opt\u001b[39m.\u001b[39mnit,opt\u001b[39m.\u001b[39mfun,opt\u001b[39m.\u001b[39mx, fid]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     \u001b[39m# return [fid]\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m GD_search_lib(show_calcs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography main March17.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     flip_algo\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# delta = abs(opt_params_1[0]-opt_params_1[1])/4                                                  # creating a buffer for new bounds\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39m# bound2 = [(i-delta, i+delta) for i in opt_params_1]                                             # buffer of size delta around each parameter\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m# opt_2 = GDlib(lnL, opt_params_1, bounds = bound2)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39m# opt_params_2 = opt_2.x\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39m# opt_params= opt_params_2\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     opt_params_2 \u001b[39m=\u001b[39m GD(opt_params_1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     opt_params\u001b[39m=\u001b[39m opt_params_2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m opt_states \u001b[39m=\u001b[39m Creating_states(opt_params)[\u001b[39m0\u001b[39m]         \u001b[39m#new correctly switched states\u001b[39;00m\n",
      "\u001b[1;32m/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography main March17.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m cost0 \u001b[39m=\u001b[39m logL(params0)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m s \u001b[39m=\u001b[39m step\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m grad_new \u001b[39m=\u001b[39m grad(params \u001b[39m=\u001b[39m params0)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m params_new \u001b[39m=\u001b[39m params0\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m values \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grad' is not defined"
     ]
    }
   ],
   "source": [
    "# Gradeint search using library method\n",
    "\n",
    "def GD_search_lib(N = 10000, params = [0,m.pi/2,0,0,m.pi/4] , params0 = [.1, .3, 0, 0, m.pi/4], show_calcs = False):\n",
    "    # idea : we are searching for the Given variables params, But they are unknowm. we search them by optimizing the lnL fn, which in turn is dependent on the collapse counts, And that's where the given parameters come into play..\n",
    "    # So basically we will Perform the numerical experiment below, And then using the collapse counts And the Abstract Analytical probabilities We create the Likelihood fn lnL. Then perform gradeient decent on it to find Optimum Parameters. \n",
    "    bounds = [(-m.pi,m.pi+.1), (-m.pi,m.pi+.1) ,(-m.pi,m.pi+.1),(-m.pi,m.pi+.1),(0,m.pi/2+.1)]\n",
    "    # Numerical experiment part\n",
    "    num_expt = num_experiment(N = N, params = params)\n",
    "    \n",
    "    states, rho, th_pr = num_expt[0], num_expt[1], num_expt[2] # for later\n",
    "    nj_vec = num_expt[3]\n",
    "    global pr                                           # importing the Analytical probabilities\n",
    "    lnL_list = [nj_vec[i]*sym.log(pr[i]) for i in range(len(pr))]        # likelihood list\n",
    "    lnL_abst = sum(lnL_list).evalf()                                  # likelihood fucntion\n",
    "    \n",
    "    # likelihood functions\n",
    "    def lnL(s_p = params0):                                    #s_p stands for search parameters\n",
    "        lnL = lnL_abst.subs({theta1: s_p[0], theta2: s_p[1] , phi1: s_p[2] , phi2: s_p[3] , alpha: s_p[4] })\n",
    "        neg_likelihood = -(lnL.evalf())\n",
    "        return neg_likelihood \n",
    "    #grad function\n",
    "    def grad(params=[0,m.pi/2,0,0,m.pi/4] , s=(1/500), show_calcs = False):    # \"point\" is the list of parameters\n",
    "        del_theta1 = lnL(params = [params[0]+s,params[1],params[2],params[3],params[4]]) - lnL(params = [params[0],params[1],params[2],params[3],params[4]])\n",
    "        del_theta2 = lnL(params = [params[0],params[1]+s,params[2],params[3],params[4]]) - lnL(params = [params[0],params[1],params[2],params[3],params[4]])\n",
    "        del_phi1   = lnL(params = [params[0],params[1],params[2]+s,params[3],params[4]]) -   lnL(params = [params[0],params[1],params[2],params[3],params[4]])\n",
    "        del_phi2   = lnL(params = [params[0],params[1],params[2],params[3]+s,params[4]]) -   lnL(params = [params[0],params[1],params[2],params[3],params[4]])\n",
    "        del_alpha  = lnL(params = [params[0],params[1],params[2],params[3],params[4]+s]) -  lnL(params = [params[0],params[1],params[2],params[3],params[4]])\n",
    "\n",
    "        grad = [del_theta1/s,del_theta2/s,del_phi1/s,del_phi2/s,del_alpha/s]\n",
    "        grad = [i if abs(i) > 1e-5 else 0 for i in grad]\n",
    "        return grad\n",
    "\n",
    "\n",
    "\n",
    "    # GDresult = GDlib(lnL, params0, bounds = bounds)\n",
    "    opt = GDlib(lnL, params0, bounds = bounds)\n",
    "    opt_params = opt.x\n",
    "    \n",
    "    # now to find the Fidelity\n",
    "    opt_states_raw = Creating_states(opt_params)[0]              #new states\n",
    "    \n",
    "    fid0, fid1 = abs(opt_states_raw[0].H*states[0])**2, abs(opt_states_raw[1].H*states[1])**2\n",
    "    fid0_cross, fid1_cross = abs(opt_states_raw[1].H*states[0])**2, abs(opt_states_raw[0].H*states[1])**2\n",
    "    \n",
    "    flip_algo = 0\n",
    "    if fid0_cross[0] + fid1_cross[0] > fid0[0]+fid1[0]:                     # adding zero because of type being matrix..\n",
    "        opt_params_1 = [opt_params[1],opt_params[0],opt_params[2],opt_params[3],opt_params[4]]        # reversing oder of theta1 and theta2 if cross fidelities are higher.\n",
    "        flip_algo= 1\n",
    "        # delta = abs(opt_params_1[0]-opt_params_1[1])/4                                                  # creating a buffer for new bounds\n",
    "        # bound2 = [(i-delta, i+delta) for i in opt_params_1]                                             # buffer of size delta around each parameter\n",
    "        # opt_2 = GDlib(lnL, opt_params_1, bounds = bound2)\n",
    "        # opt_params_2 = opt_2.x\n",
    "        # opt_params= opt_params_2\n",
    "        opt_params_2 = GD(opt_params_1)\n",
    "        opt_params= opt_params_2\n",
    "\n",
    "    opt_states = Creating_states(opt_params)[0]         #new correctly switched states\n",
    "    fid0, fid1 = abs(opt_states[0].H*states[0])**2, abs(opt_states[1].H*states[1])**2           # Correct Fidelities\n",
    "    fid_sym = [fid0, fid1]\n",
    "    fid = list((np.array(fid_sym).astype(float)).flatten())     # converting from sympy matrix to a flattened array to a list\n",
    "\n",
    "\n",
    "    if show_calcs == True:\n",
    "        # pprint(rho)\n",
    "        \n",
    "        # print(\"collapse vector\",nj_vec, \"\\ngiven parameters\\n\", params, \"\\noptimal parameters\\n\", opt_params)\n",
    "        \n",
    "        # print('\\noriginal states: \\n' )\n",
    "        # pprint(states)\n",
    "        \n",
    "        print('\\n raw states:' )\n",
    "        print(list(opt_states_raw[0]))\n",
    "        print(list(opt_states_raw[1]))\n",
    "        print('\\n final states:')\n",
    "        print(list(opt_states[0]))\n",
    "        print(list(opt_states[1]))\n",
    "        print(\"\\n Fidelities\",fid)\n",
    "        \n",
    "        print(\"\\n raw params \", opt.x)\n",
    "        print(\"\\n intermediate params \", opt_params_1)\n",
    "        print(\"\\n final params \", opt_params)\n",
    "    \n",
    "    return [opt.success,opt.nit,opt.fun,opt.x, fid]\n",
    "    # return [fid]\n",
    "\n",
    "GD_search_lib(show_calcs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-21321.3615986738\n"
     ]
    }
   ],
   "source": [
    "nj_vec = [907, 872, 1683, 812, 846, 1562, 856, 795, 1667]\n",
    "lnL_list = [nj_vec[i]*sym.log(pr[i]) for i in range(len(pr))]        # likelihood list\n",
    "lnL_abst = sum(lnL_list).evalf()                                  # likelihood fucntion\n",
    "# lnL = lnL_abst.subs({theta1: 1.5984763884144184, theta2:.3281111984575599 , phi1:-0.4380749101756176, phi2:-1.1918940940201408, alpha:0.8184139830494875 })\n",
    "lnL = lnL_abst.subs({theta1:.0991984575599 , theta2: 1.561763884144184, phi1:-0.580749101756176, phi2:-1.1918940940201408, alpha:0.8184139830494875 })\n",
    "\n",
    "# [0.3281111984575599, 1.5984763884144184, -0.4380749101756176, -1.1918940940201408, 0.8184139830494875]\n",
    "print(lnL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Likelihood fn\\n\\npr_analytical = [i.subs({theta1 : 0, theta2 : m.pi/2, phi1 : 0, phi2 : 0, alpha : m.pi/4}) for i in pr]\\nprint(\"analytical:\",pr_analytical)\\n# print(sum(pr_analytical))\\n\\n#SEMI ANALYTICAL\\nrho = Creating_states(Abstract=1)[-1]\\npr_semanl_abs = [np.trace(np.dot(rho, POVM_elts[i])) for i in range(len(POVM_elts))]\\npr_semanl = [i.subs({theta1 : 0, theta2 : m.pi/2, phi1 : 0, phi2 : 0, alpha : m.pi/4}) for i in pr_semanl_abs]\\nprint(\"semi anlt\",pr_semanl) \\n\\n\\n# Numerical\\nrho = Creating_states(Abstract=0)[-1]\\npr_num = [np.trace(np.dot(rho, POVM_elts[i])) for i in range(len(POVM_elts))]\\nprint(\"mun\",pr_num) \\n\\n\\n# numerical from the experimaent function\\npr_exp = experiment(N = 100000, theta = [0,m.pi/2])[0]\\nprint(\"exp\",pr_exp) \\n\\n#corresponding n vector\\nn = experiment(N = 100000, theta = [0,m.pi/2])[1]\\nprint(\"n vector:\",n) \\n# verified, that all methods Converge to the same probabilities.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Likelihood fn Verification:\n",
    "\n",
    "pr_analytical = [i.subs({theta1 : 0, theta2 : m.pi/2, phi1 : 0, phi2 : 0, alpha : m.pi/4}) for i in pr]\n",
    "print(\"analytical:\",pr_analytical)\n",
    "# print(sum(pr_analytical))\n",
    "\n",
    "#SEMI ANALYTICAL\n",
    "rho = Creating_states(Abstract=1)[-1]\n",
    "pr_semanl_abs = [np.trace(np.dot(rho, POVM_elts[i])) for i in range(len(POVM_elts))]\n",
    "pr_semanl = [i.subs({theta1 : 0, theta2 : m.pi/2, phi1 : 0, phi2 : 0, alpha : m.pi/4}) for i in pr_semanl_abs]\n",
    "print(\"semi anlt\",pr_semanl) \n",
    "\n",
    "\n",
    "# Numerical\n",
    "rho = Creating_states(Abstract=0)[-1]\n",
    "pr_num = [np.trace(np.dot(rho, POVM_elts[i])) for i in range(len(POVM_elts))]\n",
    "print(\"mun\",pr_num) \n",
    "\n",
    "\n",
    "# numerical from the experimaent function\n",
    "pr_exp = experiment(N = 100000, theta = [0,m.pi/2])[0]\n",
    "print(\"exp\",pr_exp) \n",
    "\n",
    "#corresponding n vector\n",
    "n = experiment(N = 100000, theta = [0,m.pi/2])[1]\n",
    "print(\"n vector:\",n) \n",
    "# verified, that all methods Converge to the same probabilities.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 236662.525117525$"
      ],
      "text/plain": [
       "236662.525117525"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining experimental n vector\n",
    "n =[8305, 16778, 8453, 8330, 16841, 8234, 8283, 16600, 8176]    # for statres [0,m.pi/2]\n",
    "n_normalized =[i/sum(n) for i in n]     # \"experimental probabililtes\"\n",
    "\n",
    "#defining likelihood expression\n",
    "lnL_list = [n[i]*sym.log(pr[i]) for i in range(len(pr))]\n",
    "lnL = sum(lnL_list)         # created the likelihood fucntion\n",
    "lnL_psuedo = sum([n[i]*m.log(n_normalized[i]) for i in range(len(n))])\n",
    "\n",
    "# print(\"ideal answer\",lnL.subs({phi1:0, phi2:0, theta1: 0, alpha: m.pi/4, theta2: m.pi/2})) # ideal answer -213681.506718260\n",
    "# print(\"psuedo answer\",lnL_psuedo)         # psuedo answer -213676.9481968622\n",
    "\n",
    "#Defining likelihood as a funciton of parameters.\n",
    "\n",
    "\n",
    "((logL([0,m.pi/4,m.pi/2,0,m.pi/4])))\n",
    "# type(((logL([0,2,0,0,m.pi/4])).evalf()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8305*log(0.166666666666667*(-2.82842712474619*sin(theta1)*cos(phi1)*cos(theta1) + cos(theta1)**2 + 1)*sin(theta1)**2*cos(alpha)**2 + 0.166666666666667*(-2.82842712474619*sin(theta2)*cos(phi2)*cos(theta2) + cos(theta2)**2 + 1)*sin(alpha)**2*sin(theta2)**2)\n",
      "-20637.1497264893\n",
      "-30062.1403747083\n",
      "-21004.9159106580\n",
      "-20699.2723927340\n",
      "-30175.0212212697\n",
      "-20460.7213543544\n",
      "-20582.4817801940\n",
      "-29743.2071891857\n",
      "-20316.5967686667\n",
      "[-20637.1497264893, -30062.1403747083, -21004.9159106580, -20699.2723927340, -30175.0212212697, -20460.7213543544, -20582.4817801940, -29743.2071891857, -20316.5967686667]\n",
      "sum -213681.506718260\n"
     ]
    }
   ],
   "source": [
    "#rough\n",
    "print(lnL_list[0])\n",
    "print(lnL_list[0].subs({phi1:0, phi2:0, theta1: 0, theta2: m.pi/2,  alpha: m.pi/4}))\n",
    "print(lnL_list[1].subs({phi1:0, phi2:0, theta1: 0, theta2: m.pi/2,  alpha: m.pi/4}))\n",
    "print(lnL_list[2].subs({phi1:0, phi2:0, theta1: 0, theta2: m.pi/2,  alpha: m.pi/4}))\n",
    "print(lnL_list[3].subs({phi1:0, phi2:0, theta1: 0, theta2: m.pi/2,  alpha: m.pi/4}))\n",
    "print(lnL_list[4].subs({phi1:0, phi2:0, theta1: 0, theta2: m.pi/2,  alpha: m.pi/4}))\n",
    "print(lnL_list[5].subs({phi1:0, phi2:0, theta1: 0, theta2: m.pi/2,  alpha: m.pi/4}))\n",
    "print(lnL_list[6].subs({phi1:0, phi2:0, theta1: 0, theta2: m.pi/2,  alpha: m.pi/4}))\n",
    "print(lnL_list[7].subs({phi1:0, phi2:0, theta1: 0, theta2: m.pi/2,  alpha: m.pi/4}))\n",
    "print(lnL_list[8].subs({phi1:0, phi2:0, theta1: 0, theta2: m.pi/2,  alpha: m.pi/4}))\n",
    "k = [i.subs({phi1:0, phi2:0, theta1: 0, theta2: m.pi/2, alpha: m.pi/4}) for i in lnL_list]\n",
    "print(k)\n",
    "print('sum', sum(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "logL() got an unexpected keyword argument 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography main March17.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# for i in grad:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m#     if i > 1e9 or i is False:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m#         print(f\"something wrong, gradient blowing up for parameter {i}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m grad\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(grad())\n",
      "\u001b[1;32m/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography main March17.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgrad\u001b[39m( params\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m,m\u001b[39m.\u001b[39mpi\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,m\u001b[39m.\u001b[39mpi\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m] ,s\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39m500\u001b[39m), show_calcs \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):    \u001b[39m# point is the list of parameter : [theta1, theta2, phi1, phi2, alpha] respectively\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     del_theta1 \u001b[39m=\u001b[39m logL(params \u001b[39m=\u001b[39;49m [params[\u001b[39m0\u001b[39;49m]\u001b[39m+\u001b[39;49ms,params[\u001b[39m1\u001b[39;49m],params[\u001b[39m2\u001b[39;49m],params[\u001b[39m3\u001b[39;49m],params[\u001b[39m4\u001b[39;49m]]) \u001b[39m-\u001b[39m logL(params \u001b[39m=\u001b[39m [params[\u001b[39m0\u001b[39m],params[\u001b[39m1\u001b[39m],params[\u001b[39m2\u001b[39m],params[\u001b[39m3\u001b[39m],params[\u001b[39m4\u001b[39m]])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     del_theta2 \u001b[39m=\u001b[39m logL(params \u001b[39m=\u001b[39m [params[\u001b[39m0\u001b[39m],params[\u001b[39m1\u001b[39m]\u001b[39m+\u001b[39ms,params[\u001b[39m2\u001b[39m],params[\u001b[39m3\u001b[39m],params[\u001b[39m4\u001b[39m]]) \u001b[39m-\u001b[39m logL(params \u001b[39m=\u001b[39m [params[\u001b[39m0\u001b[39m],params[\u001b[39m1\u001b[39m],params[\u001b[39m2\u001b[39m],params[\u001b[39m3\u001b[39m],params[\u001b[39m4\u001b[39m]])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pranjal/Desktop/Python/Research_python/Pair_disc_code/MLE_tomography%20main%20March17.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     del_phi1   \u001b[39m=\u001b[39m logL(params \u001b[39m=\u001b[39m [params[\u001b[39m0\u001b[39m],params[\u001b[39m1\u001b[39m],params[\u001b[39m2\u001b[39m]\u001b[39m+\u001b[39ms,params[\u001b[39m3\u001b[39m],params[\u001b[39m4\u001b[39m]]) \u001b[39m-\u001b[39m   logL(params \u001b[39m=\u001b[39m [params[\u001b[39m0\u001b[39m],params[\u001b[39m1\u001b[39m],params[\u001b[39m2\u001b[39m],params[\u001b[39m3\u001b[39m],params[\u001b[39m4\u001b[39m]])\n",
      "\u001b[0;31mTypeError\u001b[0m: logL() got an unexpected keyword argument 'params'"
     ]
    }
   ],
   "source": [
    "#defining gradient function\n",
    "def grad( params=[0,m.pi/2,0,0,m.pi/4] ,s=(1/500), show_calcs = False):    # point is the list of parameter : [theta1, theta2, phi1, phi2, alpha] respectively\n",
    "    \n",
    "    del_theta1 = logL(params = [params[0]+s,params[1],params[2],params[3],params[4]]) - logL(params = [params[0],params[1],params[2],params[3],params[4]])\n",
    "    del_theta2 = logL(params = [params[0],params[1]+s,params[2],params[3],params[4]]) - logL(params = [params[0],params[1],params[2],params[3],params[4]])\n",
    "    del_phi1   = logL(params = [params[0],params[1],params[2]+s,params[3],params[4]]) -   logL(params = [params[0],params[1],params[2],params[3],params[4]])\n",
    "    del_phi2   = logL(params = [params[0],params[1],params[2],params[3]+s,params[4]]) -   logL(params = [params[0],params[1],params[2],params[3],params[4]])\n",
    "    del_alpha  = logL(params = [params[0],params[1],params[2],params[3],params[4]+s]) -  logL(params = [params[0],params[1],params[2],params[3],params[4]])\n",
    "\n",
    "    grad = [del_theta1/s,del_theta2/s,del_phi1/s,del_phi2/s,del_alpha/s]\n",
    "    grad = [i if abs(i) > 1e-5 else 0 for i in grad]\n",
    "    # for i in grad:\n",
    "    #     if i > 1e9 or i is False:\n",
    "    #         print(f\"something wrong, gradient blowing up for parameter {i}\")\n",
    "    return grad\n",
    "print(grad())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original 205479.837211471\n",
      "new 213681.506718260\n",
      "grad [43961.3730165001, -42927.3838519148, -5530.56985090370, 1766.54624816729, 8904.13081909355]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1.5707963267948966, 0, 0, 0.7853981633974483]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rough\n",
    "s = 1/200\n",
    "\n",
    "a = [-3.739e-01, 1.595e+00, 1.346e+00, -1.553e+00, 7.458e-01]\n",
    "b = [0, m.pi/2, 0, 0, m.pi/4]\n",
    "v0 = \"original\",logL(a)\n",
    "v1 = \"new\",logL(b)\n",
    "\n",
    "print(\"original\",logL(a))\n",
    "print(\"new\",logL(b))\n",
    "\n",
    "print(\"grad\",grad([-0.4, .195, .346, -.553, 0.7458]))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grad descent\n",
    "params_manual = [0,1,0,0,m.pi/4] # same \n",
    "def GD(param0 = [0,m.pi/2,0,0,m.pi/4], nit = 30, step = 1/200, show_calc = False):\n",
    "    cost0 = logL(params0)\n",
    "    s = step\n",
    "    grad_new = grad(params = params0)\n",
    "    params_new = params0\n",
    "    values = []\n",
    "    for i in range(nit):\n",
    "        params_new = [params_new[i]-s*(grad_new[i]/8000) for i in range(len(params0))]\n",
    "        grad_new = grad(params_new)\n",
    "        value = [logL(params_new), params_new, grad_new, i]\n",
    "        values.append(value)\n",
    "        \n",
    "        if i > (3/10)*nit//1 and i > 10:\n",
    "            s = 5*step\n",
    "            if i > (8/10)*nit//1:\n",
    "                s = 15*step\n",
    "\n",
    "        if show_calc == True:\n",
    "            print(value,'\\n ')\n",
    "    return params_new\n",
    "\n",
    "# GD(param0= params_manual, nit= 150, step = 1/200, show_calc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.742651516759416"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [0, 1.5707963267948966, 0, 0, 0.7853981633974483]\n",
    "#  [-0.0453554437925232, 1.56970457797804, 0.0969275280091279, -0.00179414849833847, 0.784096793392809]\n",
    "#  [-0.372572520872864, 1.55890221385790, 1.23967731543922, 0.00149623378345495, 0.746416071840694]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 17917.4628513275\n",
       "        x: [ 2.384e-03  1.568e+00  2.519e-08 -4.660e-01  1.571e+00]\n",
       "      nit: 7\n",
       "      jac: [ 0.000e+00  7.640e-02  0.000e+00  3.372e-01  1.033e-01]\n",
       "     nfev: 54\n",
       "     njev: 9\n",
       " hess_inv: <5x5 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n =[8305, 16778, 8453, 8330, 16841, 8234, 8283, 16600, 8176]    # for statres [0,m.pi/2]\n",
    "n = [1678, 0, 1639, 1656, 0, 1662, 1723, 0, 1642]\n",
    "# n_normalized =[i/sum(n) for i in n]     # \"experimental probabililtes\"\n",
    "\n",
    "#defining likelihood expression\n",
    "lnL_list = [n[i]*sym.log(pr[i]) for i in range(len(pr))]\n",
    "lnL = sum(lnL_list)         # created the likelihood fucntion\n",
    "# lnL_psuedo = sum([n[i]*m.log(n_normalized[i]) for i in range(len(n))])\n",
    "\n",
    "\n",
    "#Defining likelihood as a funciton of parameters.\n",
    "def logL(p):\n",
    "    k = lnL.subs({theta1: p[0], theta2: p[1], phi1: p[2], phi2: p[3], alpha: p[4]})\n",
    "    return -k.evalf()\n",
    "\n",
    "# ((logL([0,m.pi/4,m.pi/2,0,m.pi/4])))\n",
    "# type(((logL([0,2,0,0,m.pi/4])).evalf()))\n",
    "\n",
    "params0 = [0,1,0,0,m.pi/4]\n",
    "bounds = [(-1,1), (-m.pi/2+m.pi/180,m.pi+m.pi/180),(-m.pi/2+m.pi/180,m.pi+m.pi/180),(-m.pi/2+m.pi/180,m.pi+m.pi/180),(-m.pi/2+m.pi/180,m.pi+m.pi/180)]\n",
    "\n",
    "opt = GDlib(logL, params0, bounds= bounds)\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⎡⎡          0.930907673429997           ⎤  ⎡         -0.0239573001262181      \n",
      "⎢⎢                                      ⎥  ⎢                                  \n",
      "⎢⎢                    1.34611426055477⋅ⅈ⎥, ⎢                   -1.553343034274\n",
      "⎣⎣-0.365254573618387⋅ℯ                  ⎦  ⎣0.999712982695865⋅ℯ               \n",
      "\n",
      "    ⎤⎤\n",
      "    ⎥⎥\n",
      "95⋅ⅈ⎥⎥\n",
      "    ⎦⎦\n",
      "⎡⎡1⎤  ⎡ 0 ⎤⎤\n",
      "⎢⎢ ⎥, ⎢   ⎥⎥\n",
      "⎣⎣0⎦  ⎣1.0⎦⎦\n",
      "[[0.86658909645085], [0.999426047770662]]\n"
     ]
    }
   ],
   "source": [
    "s = Creating_states(params = opt.x)[0]\n",
    "t = Creating_states()[0]\n",
    "\n",
    "pprint(s)\n",
    "pprint(t)\n",
    "# sym.pprint(s)\n",
    "\n",
    "fid1 = abs(sym.Matrix(s[0]).H*t[0])**2\n",
    "fid2 = abs(sym.Matrix(s[1]).H*t[1])**2\n",
    "fid = [fid1, fid2]\n",
    "pprint(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Matrix([\n",
       " [                         0.930907673429997],\n",
       " [-0.365254573618387*exp(1.34611426055477*I)]]),\n",
       " Matrix([\n",
       " [                       -0.0239573001262181],\n",
       " [0.999712982695865*exp(-1.55334303427495*I)]])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GDSearch(params0 = [0,1,0,0,m.pi/4], bounds = [(-1,1), (-m.pi/2+m.pi/180,m.pi+m.pi/180),(-m.pi/2+m.pi/180,m.pi+m.pi/180),(-m.pi/2+m.pi/180,m.pi+m.pi/180),(-m.pi/2+m.pi/180,m.pi+m.pi/180)]):\n",
    "    result = GDlib(logL, params0, bounds= bounds)\n",
    "    params = result.x\n",
    "    vecs = Creating_states(params = params, Abstract = 0)[0]\n",
    "    if result.success is not True:\n",
    "        print(\"\\n CHECK \\n- didnt succeed? \\n \")\n",
    "    phi1_num, phi2_num = sym.Matrix(vecs[0]), sym.Matrix(vecs[1])\n",
    "    return([phi1_num, phi2_num], result)\n",
    "\n",
    "GDSearch()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
